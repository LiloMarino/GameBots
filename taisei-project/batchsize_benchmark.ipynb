{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d393b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================================\n",
    "# CONFIGURAÇÕES\n",
    "# =======================================\n",
    "DATASET_PATH = \"../../LabelStudio/dataset/data.yaml\"\n",
    "IMAGE_SIZE = 640\n",
    "EPOCHS = 3  # menos épocas só para medir\n",
    "DEVICE = 0  # 0 = CUDA:0\n",
    "RESULTS_DIR = Path(\"benchmark_batchsize\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Modelo leve para benchmark\n",
    "MODEL = \"yolov5n.pt\"\n",
    "\n",
    "# Batch sizes para testar\n",
    "BATCH_SIZES = [x for x in range(1, 65)]\n",
    "\n",
    "# =======================================\n",
    "# FUNÇÃO: Treinar e medir tempo + memória\n",
    "# =======================================\n",
    "def benchmark_batch(batch_size):\n",
    "    model = YOLO(MODEL)\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    start = time.perf_counter_ns()\n",
    "    results = model.train(\n",
    "        data=DATASET_PATH,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMAGE_SIZE,\n",
    "        batch=batch_size,\n",
    "        workers=1,\n",
    "        device=DEVICE,\n",
    "        patience=2,\n",
    "        save=False,\n",
    "        pretrained=True\n",
    "    )\n",
    "    total_time = time.perf_counter_ns() - start\n",
    "    time_per_epoch = total_time / EPOCHS\n",
    "\n",
    "    # medir memória máxima alocada (em MB)\n",
    "    max_mem = torch.cuda.max_memory_allocated(device=DEVICE) / (1024**2)\n",
    "\n",
    "    return time_per_epoch, max_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa4185c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Benchmarking batch size 1 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train21, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train21, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 224.247.7 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 229.037.5 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train21\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train21\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3     0.412G      2.064      3.007      1.066         66        640: 100%|██████████| 505/505 [00:37<00:00, 13.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:00<00:00, 25.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.718      0.719      0.791       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3     0.414G      1.693      1.651     0.9832         15        640: 100%|██████████| 505/505 [00:35<00:00, 14.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:00<00:00, 26.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.828      0.782       0.87      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3     0.414G      1.578      1.383      0.964         11        640: 100%|██████████| 505/505 [00:36<00:00, 13.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:00<00:00, 26.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.917      0.794      0.889      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train21\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train21\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train21\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:00<00:00, 33.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.917      0.793      0.888      0.584\n",
      "                Bullet         35        524      0.901      0.536      0.731      0.354\n",
      "                 Enemy         46        153      0.951      0.863      0.948      0.703\n",
      "                Player         48         48      0.899      0.979      0.985      0.696\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train21\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 2 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train23, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train23, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 227.945.8 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 238.239.9 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train23\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train23\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3     0.717G      2.069      2.774      1.038         49        640: 100%|██████████| 253/253 [00:21<00:00, 11.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:00<00:00, 20.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.935      0.605      0.826      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      0.77G      1.708      1.506     0.9657         13        640: 100%|██████████| 253/253 [00:20<00:00, 12.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:00<00:00, 21.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.877      0.756      0.874      0.575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      0.77G      1.554      1.257     0.9364         37        640: 100%|██████████| 253/253 [00:19<00:00, 12.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:00<00:00, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.869      0.796      0.881      0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.018 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train23\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train23\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train23\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:00<00:00, 18.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725       0.87      0.795      0.881      0.587\n",
      "                Bullet         35        524      0.892      0.462      0.695       0.36\n",
      "                 Enemy         46        153      0.805      0.943      0.961       0.72\n",
      "                Player         48         48      0.913      0.979      0.986      0.681\n",
      "Speed: 0.9ms preprocess, 6.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train23\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 3 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=3, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train24, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train24, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 249.050.9 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 249.633.5 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train24\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0004921875), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train24\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      1.05G      2.017      2.754      1.024         51        640: 100%|██████████| 169/169 [00:15<00:00, 10.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:00<00:00, 17.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.802      0.752      0.821      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3       1.2G      1.633      1.398     0.9493         12        640: 100%|██████████| 169/169 [00:15<00:00, 10.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:00<00:00, 17.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.876      0.785      0.891      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3       1.2G      1.489      1.205     0.9248         22        640: 100%|██████████| 169/169 [00:15<00:00, 10.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:00<00:00, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.933      0.789        0.9      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train24\\weights\\last.pt, 5.2MB\n",
      "\n",
      "=== Benchmarking batch size 4 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train25, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train25, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 256.955.8 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 253.039.9 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train25\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train25\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      1.26G      2.043       2.74      1.018         50        640: 100%|██████████| 127/127 [00:13<00:00,  9.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:00<00:00, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.875      0.687      0.818      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      1.38G      1.663      1.401     0.9595         11        640: 100%|██████████| 127/127 [00:12<00:00,  9.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:00<00:00, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.894       0.73      0.875      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      1.38G       1.56      1.235     0.9265         18        640: 100%|██████████| 127/127 [00:13<00:00,  9.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:00<00:00, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.872       0.78      0.882      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train25\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train25\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train25\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:00<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.873      0.781      0.882      0.598\n",
      "                Bullet         35        524      0.944      0.417        0.7      0.355\n",
      "                 Enemy         46        153      0.822      0.948       0.96      0.734\n",
      "                Player         48         48      0.853      0.979      0.984      0.706\n",
      "Speed: 0.4ms preprocess, 2.8ms inference, 0.0ms loss, 7.6ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train25\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 5 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=5, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train26, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train26, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 155.336.6 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 206.853.7 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train26\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005078125), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train26\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      1.54G      2.083      2.824      1.029        122        640: 100%|██████████| 101/101 [00:11<00:00,  8.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.763      0.529      0.701      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      1.54G      1.656      1.426     0.9438        174        640: 100%|██████████| 101/101 [00:11<00:00,  8.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.839      0.791      0.879      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      1.78G      1.496      1.213      0.925         75        640: 100%|██████████| 101/101 [00:11<00:00,  8.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.922      0.811      0.905      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train26\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train26\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train26\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.922      0.811      0.905      0.606\n",
      "                Bullet         35        524      0.965      0.519      0.762      0.392\n",
      "                 Enemy         46        153      0.841      0.935      0.965      0.741\n",
      "                Player         48         48      0.959      0.979      0.989      0.684\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 0.0ms loss, 9.9ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train26\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 6 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=6, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train27, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train27, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 248.558.0 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 233.746.9 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train27\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.000515625), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train27\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      1.99G      2.066      2.846      1.027         53        640: 100%|██████████| 85/85 [00:11<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.875      0.526       0.74      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      2.22G      1.621      1.381     0.9484         11        640: 100%|██████████| 85/85 [00:11<00:00,  7.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.861      0.742      0.874      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      2.23G      1.483      1.166     0.9239         11        640: 100%|██████████| 85/85 [00:10<00:00,  7.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.905      0.803        0.9       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train27\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train27\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train27\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.905      0.803        0.9      0.609\n",
      "                Bullet         35        524      0.931      0.488      0.742      0.374\n",
      "                 Enemy         46        153      0.868      0.943      0.969      0.741\n",
      "                Player         48         48      0.918      0.979       0.99      0.713\n",
      "Speed: 1.1ms preprocess, 2.9ms inference, 0.0ms loss, 11.3ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train27\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 7 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=7, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train28, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train28, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 235.444.0 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 252.138.4 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train28\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0004921875), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train28\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      2.09G       2.08      2.926      1.034         58        640: 100%|██████████| 73/73 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.871      0.257      0.566      0.337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      2.09G      1.625      1.404     0.9447         11        640: 100%|██████████| 73/73 [00:10<00:00,  6.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.871       0.75      0.867      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      2.09G      1.488       1.16     0.9208         12        640: 100%|██████████| 73/73 [00:10<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.904      0.814      0.894      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train28\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train28\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train28\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.903      0.815      0.894      0.605\n",
      "                Bullet         35        524      0.892      0.519      0.722      0.375\n",
      "                 Enemy         46        153      0.858      0.928      0.966       0.75\n",
      "                Player         48         48       0.96      0.998      0.994       0.69\n",
      "Speed: 1.0ms preprocess, 3.5ms inference, 0.0ms loss, 11.2ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train28\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 8 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train29, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train29, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 239.149.0 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 220.743.6 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train29\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train29\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      2.55G      2.093      2.936      1.038         65        640: 100%|██████████| 64/64 [00:10<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.796      0.207       0.56      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      2.55G      1.658      1.392     0.9544         14        640: 100%|██████████| 64/64 [00:09<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.881      0.749      0.862      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      2.55G      1.491      1.157     0.9284         12        640: 100%|██████████| 64/64 [00:09<00:00,  6.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.919       0.79      0.892      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train29\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train29\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train29\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.922      0.788      0.892      0.584\n",
      "                Bullet         35        524      0.916      0.473      0.721      0.365\n",
      "                 Enemy         46        153      0.875      0.913      0.963      0.723\n",
      "                Player         48         48      0.977      0.979      0.993      0.665\n",
      "Speed: 1.0ms preprocess, 4.1ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train29\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 9 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=9, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train30, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train30, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 248.756.4 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 255.339.0 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train30\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0004921875), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train30\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      3.06G      2.111      3.002      1.034         52        640: 100%|██████████| 57/57 [00:10<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.984      0.089      0.432      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      2.88G      1.645      1.425     0.9513         17        640: 100%|██████████| 57/57 [00:09<00:00,  5.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.912        0.7      0.861      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      3.47G        1.5      1.203     0.9215         10        640: 100%|██████████| 57/57 [00:09<00:00,  5.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.901      0.799      0.894      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train30\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train30\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train30\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.902      0.799      0.895      0.592\n",
      "                Bullet         35        524      0.939      0.468      0.725      0.372\n",
      "                 Enemy         46        153      0.849      0.928      0.966      0.717\n",
      "                Player         48         48      0.918          1      0.993      0.688\n",
      "Speed: 1.0ms preprocess, 2.8ms inference, 0.0ms loss, 10.5ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train30\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 10 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=10, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train31, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train31, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 233.646.8 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 254.230.9 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train31\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.00046875), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train31\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      3.41G      2.115      3.017      1.035        111        640: 100%|██████████| 51/51 [00:10<00:00,  4.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.671      0.419      0.403      0.251\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3       2.9G      1.648      1.425     0.9475        158        640: 100%|██████████| 51/51 [00:09<00:00,  5.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.929      0.674      0.853      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3       2.9G      1.531      1.209     0.9233         75        640: 100%|██████████| 51/51 [00:09<00:00,  5.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.894      0.798      0.888      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train31\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train31\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train31\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.894      0.795      0.888      0.585\n",
      "                Bullet         35        524      0.869       0.49      0.709      0.343\n",
      "                 Enemy         46        153      0.898      0.917      0.965      0.728\n",
      "                Player         48         48      0.917      0.979      0.991      0.684\n",
      "Speed: 0.2ms preprocess, 2.8ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train31\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 11 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=11, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train33, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train33, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 250.956.1 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 252.233.9 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train33\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.000515625), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train33\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      3.48G      2.109      3.066       1.04        224        640: 100%|██████████| 46/46 [00:10<00:00,  4.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.488      0.418      0.374      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      3.17G      1.647      1.453     0.9462        381        640: 100%|██████████| 46/46 [00:09<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.949      0.556      0.819      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      2.98G      1.527      1.196     0.9266        364        640: 100%|██████████| 46/46 [00:09<00:00,  4.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.907      0.802      0.882       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train33\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train33\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train33\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.907      0.802      0.881       0.59\n",
      "                Bullet         35        524      0.864      0.525      0.695      0.345\n",
      "                 Enemy         46        153      0.859      0.928      0.964      0.739\n",
      "                Player         48         48          1      0.952      0.985      0.685\n",
      "Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train33\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 12 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=12, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train34, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train34, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 144.349.9 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 198.170.3 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train34\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.00046875), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train34\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      3.69G      2.166      3.114       1.04        157        640: 100%|██████████| 43/43 [00:10<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.579      0.549      0.388      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      3.67G      1.652      1.446     0.9441         11        640: 100%|██████████| 43/43 [00:10<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.989      0.495      0.834      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      3.69G       1.49       1.19      0.919         18        640: 100%|██████████| 43/43 [00:10<00:00,  4.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.893      0.772      0.886      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train34\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train34\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train34\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:00<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.893      0.772      0.887      0.592\n",
      "                Bullet         35        524      0.923      0.409      0.717      0.362\n",
      "                 Enemy         46        153       0.81      0.928       0.96      0.703\n",
      "                Player         48         48      0.948      0.979      0.983      0.711\n",
      "Speed: 0.2ms preprocess, 3.9ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train34\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 13 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=13, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train35, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train35, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 250.458.4 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 170.282.3 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train35\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005078125), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train35\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      3.93G      2.134      3.122      1.033        173        640: 100%|██████████| 39/39 [00:10<00:00,  3.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0151       0.66      0.329      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      3.89G      1.664      1.474     0.9444        372        640: 100%|██████████| 39/39 [00:09<00:00,  3.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.991      0.294      0.803      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      3.84G      1.517      1.206     0.9236        426        640: 100%|██████████| 39/39 [00:09<00:00,  4.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.934      0.713      0.863      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train35\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train35\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train35\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.934      0.712      0.863      0.569\n",
      "                Bullet         35        524      0.907      0.297       0.65      0.299\n",
      "                 Enemy         46        153      0.909      0.902      0.952      0.701\n",
      "                Player         48         48      0.987      0.938      0.988      0.707\n",
      "Speed: 0.2ms preprocess, 2.9ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train35\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 14 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=14, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train36, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train36, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 246.656.1 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 264.032.3 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train36\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.000546875), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train36\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3       4.1G      2.152      3.158      1.044         35        640: 100%|██████████| 37/37 [00:10<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0173       0.67      0.296      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      4.03G      1.722      1.528     0.9569         14        640: 100%|██████████| 37/37 [00:09<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.983      0.274      0.806      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      4.12G      1.549      1.228     0.9266         11        640: 100%|██████████| 37/37 [00:09<00:00,  3.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.936      0.745      0.878      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train36\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train36\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train36\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.936      0.745      0.878      0.581\n",
      "                Bullet         35        524      0.951      0.368      0.691      0.353\n",
      "                 Enemy         46        153      0.936      0.908      0.957       0.69\n",
      "                Player         48         48       0.92      0.959      0.985        0.7\n",
      "Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train36\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 15 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=15, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train37, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train37, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 236.849.4 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 246.835.0 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train37\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.00046875), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train37\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      4.25G      2.126      3.182       1.04        296        640: 100%|██████████| 34/34 [00:10<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0132       0.62      0.281      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      4.17G      1.661      1.487     0.9437        352        640: 100%|██████████| 34/34 [00:09<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725          1      0.191      0.793      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      4.27G      1.493      1.199     0.9194        314        640: 100%|██████████| 34/34 [00:09<00:00,  3.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.958      0.705      0.877      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train37\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train37\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train37\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.959      0.705      0.877      0.586\n",
      "                Bullet         35        524      0.929      0.342      0.691       0.36\n",
      "                 Enemy         46        153      0.948      0.828      0.953      0.713\n",
      "                Player         48         48          1      0.947      0.988      0.687\n",
      "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train37\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 16 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train38, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train38, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 249.554.8 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 244.316.4 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train38\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train38\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      5.05G      2.174      3.208      1.046        217        640: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0147      0.518      0.212       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      4.59G       1.68       1.52     0.9454        342        640: 100%|██████████| 32/32 [00:13<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725          1       0.22      0.765      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      4.48G      1.499      1.203     0.9234        274        640: 100%|██████████| 32/32 [00:11<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.966      0.659      0.885      0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train38\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train38\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train38\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.966      0.659      0.886      0.587\n",
      "                Bullet         35        524       0.95       0.29      0.701       0.37\n",
      "                 Enemy         46        153      0.949      0.869      0.972      0.708\n",
      "                Player         48         48          1      0.818      0.983      0.683\n",
      "Speed: 0.2ms preprocess, 2.7ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train38\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 17 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=17, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train39, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train39, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 240.746.2 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 239.533.4 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train39\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.00053125), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train39\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      5.44G      2.177      3.249      1.051        183        640: 100%|██████████| 30/30 [00:22<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0124       0.54      0.168     0.0762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      5.54G      1.664      1.517     0.9451        579        640: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.993      0.198      0.634       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      4.96G      1.513      1.192     0.9176        465        640: 100%|██████████| 30/30 [00:25<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.988       0.53      0.847      0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train39\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train39\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train39\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.988      0.529      0.847      0.546\n",
      "                Bullet         35        524      0.964     0.0512      0.605      0.293\n",
      "                 Enemy         46        153          1      0.688      0.956      0.696\n",
      "                Player         48         48          1      0.849      0.981      0.649\n",
      "Speed: 0.4ms preprocess, 11.8ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train39\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 18 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=18, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train40, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train40, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 214.853.8 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 236.869.4 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train40\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005625000000000001), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train40\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      5.26G       2.19      3.275      1.051         66        640: 100%|██████████| 29/29 [00:14<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0107       0.41      0.194      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      5.25G      1.687       1.53     0.9462         19        640: 100%|██████████| 29/29 [00:14<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.834      0.647      0.696      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3       5.2G      1.518      1.244     0.9302         11        640: 100%|██████████| 29/29 [00:13<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725       0.99      0.409      0.839      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train40\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train40\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train40\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.989      0.408       0.84      0.554\n",
      "                Bullet         35        524      0.968     0.0584      0.587      0.295\n",
      "                 Enemy         46        153          1      0.655      0.959      0.699\n",
      "                Player         48         48          1      0.511      0.974      0.669\n",
      "Speed: 0.2ms preprocess, 3.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train40\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 19 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=19, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train41, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train41, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 207.170.4 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 257.953.7 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train41\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.00044531249999999996), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train41\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      5.28G      2.171      3.329      1.054        336        640: 100%|██████████| 27/27 [00:15<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0116      0.492      0.237      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      5.21G      1.699      1.558     0.9451        346        640: 100%|██████████| 27/27 [00:13<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.026      0.729      0.637       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      5.52G      1.521      1.206     0.9246        306        640: 100%|██████████| 27/27 [00:18<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.996      0.423      0.844      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train41\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train41\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train41\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.996      0.423      0.844      0.545\n",
      "                Bullet         35        524          1     0.0141      0.604      0.302\n",
      "                 Enemy         46        153      0.989      0.599      0.962      0.705\n",
      "                Player         48         48          1      0.654      0.965      0.628\n",
      "Speed: 0.2ms preprocess, 3.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train41\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 20 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=20, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 254.057.7 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 237.134.2 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train42\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.00046875), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train42\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      5.53G      2.171      3.359      1.051        117        640: 100%|██████████| 26/26 [00:20<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.012      0.556      0.264      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      5.31G      1.677      1.565     0.9473        155        640: 100%|██████████| 26/26 [00:15<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0266      0.736      0.622      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      5.38G      1.525      1.232     0.9251         63        640: 100%|██████████| 26/26 [00:16<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.996      0.288      0.824      0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train42\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train42\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train42\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.996      0.288      0.825      0.534\n",
      "                Bullet         35        524          1     0.0113      0.545      0.258\n",
      "                 Enemy         46        153      0.988      0.548      0.959      0.707\n",
      "                Player         48         48          1      0.306       0.97      0.635\n",
      "Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train42\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 21 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=21, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train43, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train43, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 249.655.7 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 242.660.0 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train43\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0004921875), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train43\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      5.95G      2.215      3.432      1.062         37        640: 100%|██████████| 25/25 [00:31<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.012      0.526      0.197      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      5.92G      1.693       1.58     0.9483         20        640: 100%|██████████| 25/25 [00:27<00:00,  1.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0265      0.713      0.554      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      5.86G       1.62      1.882     0.9663          1        640: 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.965      0.578      0.805      0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train43\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train43\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train43\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.965      0.578      0.805      0.501\n",
      "                Bullet         35        524      0.986      0.136      0.522      0.273\n",
      "                 Enemy         46        153      0.921      0.869      0.948      0.665\n",
      "                Player         48         48      0.988      0.729      0.946      0.564\n",
      "Speed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train43\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 22 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=22, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train44, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train44, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 184.853.3 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 250.340.5 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train44\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.000515625), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train44\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      6.92G      2.213       3.53      1.067        593        640: 100%|██████████| 23/23 [00:44<00:00,  1.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0118      0.498      0.145     0.0459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      7.25G      1.692      1.574     0.9429        507        640: 100%|██████████| 23/23 [00:38<00:00,  1.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0233      0.722      0.539      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      5.83G      1.515      1.246     0.9175        562        640: 100%|██████████| 23/23 [00:35<00:00,  1.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.033      0.824      0.777      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train44\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train44\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train44\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725      0.033      0.824      0.776      0.516\n",
      "                Bullet         35        524     0.0439      0.525      0.429       0.23\n",
      "                 Enemy         46        153     0.0462      0.967      0.939      0.699\n",
      "                Player         48         48    0.00898      0.979      0.961       0.62\n",
      "Speed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train44\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 23 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=23, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train45, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train45, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 222.529.6 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 236.136.4 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train45\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005390625), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train45\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      5.89G      2.232      3.616      1.076        589        640: 100%|██████████| 22/22 [00:42<00:00,  1.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0096      0.406     0.0779     0.0178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      6.73G      1.693       1.58     0.9429        764        640: 100%|██████████| 22/22 [00:46<00:00,  2.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0213      0.654      0.414      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      5.92G      1.523      1.239     0.9188        608        640: 100%|██████████| 22/22 [00:41<00:00,  1.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0325      0.836       0.78      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train45\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train45\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train45\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0325      0.836      0.781      0.507\n",
      "                Bullet         35        524     0.0457      0.563       0.44      0.241\n",
      "                 Enemy         46        153     0.0417      0.967      0.945      0.693\n",
      "                Player         48         48       0.01      0.979      0.957      0.587\n",
      "Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train45\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 24 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=24, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train46, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train46, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 234.952.4 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 241.337.8 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train46\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005625000000000001), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train46\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      6.22G      2.236      3.612      1.067         68        640: 100%|██████████| 22/22 [00:52<00:00,  2.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725    0.00992       0.39     0.0706     0.0205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      6.77G      1.708      1.626     0.9419         18        640: 100%|██████████| 22/22 [00:47<00:00,  2.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0249      0.629      0.445      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      6.44G      1.563      1.351     0.9555          2        640: 100%|██████████| 22/22 [00:45<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0342      0.841      0.788      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.041 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train46\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train46\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train46\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0342      0.842      0.788      0.532\n",
      "                Bullet         35        524     0.0437      0.586      0.479      0.257\n",
      "                 Enemy         46        153      0.049      0.961      0.934      0.691\n",
      "                Player         48         48     0.0101      0.979      0.951      0.648\n",
      "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train46\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 25 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=25, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train47, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train47, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 246.959.4 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 246.522.1 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train47\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005859375000000001), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train47\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      6.33G      2.221      3.666      1.078        255        640: 100%|██████████| 21/21 [00:49<00:00,  2.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725    0.00967      0.364     0.0824      0.034\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      6.87G      1.704      1.593     0.9414        197        640: 100%|██████████| 21/21 [01:09<00:00,  3.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0223      0.713        0.4      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3      6.34G      1.504      1.224     0.9218         90        640: 100%|██████████| 21/21 [01:04<00:00,  3.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0317      0.836      0.771      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.052 hours.\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train47\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train47\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train47\\weights\\best.pt...\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        725     0.0317      0.836      0.772      0.506\n",
      "                Bullet         35        524     0.0515       0.55      0.404      0.216\n",
      "                 Enemy         46        153     0.0332       0.98       0.94      0.674\n",
      "                Player         48         48     0.0102      0.979       0.97      0.628\n",
      "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train47\u001b[0m\n",
      "\n",
      "=== Benchmarking batch size 26 ===\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.183  Python-3.13.7 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=26, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../LabelStudio/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train48, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train48, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 235.549.6 MB/s, size: 24.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\train\\labels.cache... 505 images, 0 backgrounds, 0 corrupt: 100%|██████████| 505/505 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 238.755.6 MB/s, size: 25.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Usuario\\Desktop\\Faculdade\\LabelStudio\\dataset\\valid\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train48\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.00040625000000000004), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\runs\\detect\\train48\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      6.66G      2.378      4.399      1.175        722        640:  50%|█████     | 10/20 [00:39<00:39,  3.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bs \u001b[38;5;129;01min\u001b[39;00m BATCH_SIZES:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Benchmarking batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     time_per_epoch, max_mem = \u001b[43mbenchmark_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     results_list.append({\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: bs,\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtime_per_epoch_ns\u001b[39m\u001b[33m\"\u001b[39m: time_per_epoch,\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax_memory_MB\u001b[39m\u001b[33m\"\u001b[39m: max_mem\n\u001b[32m     14\u001b[39m     })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mbenchmark_batch\u001b[39m\u001b[34m(batch_size)\u001b[39m\n\u001b[32m     31\u001b[39m torch.cuda.reset_peak_memory_stats()\n\u001b[32m     33\u001b[39m start = time.perf_counter_ns()\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMAGE_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     44\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m total_time = time.perf_counter_ns() - start\n\u001b[32m     46\u001b[39m time_per_epoch = total_time / EPOCHS\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:799\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    796\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    798\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:435\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n\u001b[32m    434\u001b[39m     loss_length = \u001b[38;5;28mself\u001b[39m.tloss.shape[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.tloss.shape) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[43mpbar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_description\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%11s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%11.4g\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m.3g\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43mG\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (GB) GPU memory util\u001b[39;49;00m\n\u001b[32m    440\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloss_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# losses\u001b[39;49;00m\n\u001b[32m    441\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# batch size, i.e. 8\u001b[39;49;00m\n\u001b[32m    442\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# imgsz, i.e 640\u001b[39;49;00m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m     \u001b[38;5;28mself\u001b[39m.run_callbacks(\u001b[33m\"\u001b[39m\u001b[33mon_batch_end\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.plots \u001b[38;5;129;01mand\u001b[39;00m ni \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.plot_idx:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Desktop\\Faculdade\\GameBots\\venv\\Lib\\site-packages\\tqdm\\std.py:1382\u001b[39m, in \u001b[36mtqdm.set_description\u001b[39m\u001b[34m(self, desc, refresh)\u001b[39m\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_miniters = EMA(\u001b[38;5;28mself\u001b[39m.smoothing)\n\u001b[32m   1380\u001b[39m     \u001b[38;5;28mself\u001b[39m.refresh()\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_description\u001b[39m(\u001b[38;5;28mself\u001b[39m, desc=\u001b[38;5;28;01mNone\u001b[39;00m, refresh=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1383\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1384\u001b[39m \u001b[33;03m    Set/modify description of the progress bar.\u001b[39;00m\n\u001b[32m   1385\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1390\u001b[39m \u001b[33;03m        Forces refresh [default: True].\u001b[39;00m\n\u001b[32m   1391\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1392\u001b[39m     \u001b[38;5;28mself\u001b[39m.desc = desc + \u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m desc \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# LOOP PRINCIPAL\n",
    "# =======================================\n",
    "results_list = []\n",
    "\n",
    "for bs in BATCH_SIZES:\n",
    "    print(f\"\\n=== Benchmarking batch size {bs} ===\")\n",
    "    time_per_epoch, max_mem = benchmark_batch(bs)\n",
    "\n",
    "    results_list.append({\n",
    "        \"batch_size\": bs,\n",
    "        \"time_per_epoch_ns\": time_per_epoch,\n",
    "        \"max_memory_MB\": max_mem\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados brutos:\n",
      "    batch_size  time_per_epoch_ns  max_memory_MB\n",
      "0            1       4.111403e+10     379.630859\n",
      "1            2       2.550289e+10     599.884277\n",
      "2            3       1.869839e+10     836.625000\n",
      "3            4       1.739183e+10    1121.714844\n",
      "4            5       1.579805e+10    1317.850586\n",
      "5            6       1.522651e+10    1695.907227\n",
      "6            7       1.595303e+10    1771.418457\n",
      "7            8       1.447943e+10    1996.020996\n",
      "8            9       1.621322e+10    2447.540527\n",
      "9           10       1.402506e+10    2495.344727\n",
      "10          11       1.410068e+10    2715.883301\n",
      "11          12       1.489055e+10    2903.311523\n",
      "12          13       1.419309e+10    3249.715332\n",
      "13          14       1.442966e+10    3353.906738\n",
      "14          15       1.460644e+10    3642.287598\n",
      "15          16       2.113056e+10    4251.393555\n",
      "16          17       3.159372e+10    4587.279297\n",
      "17          18       1.924624e+10    4238.745117\n",
      "18          19       2.026195e+10    4522.575684\n",
      "19          20       2.170422e+10    4815.868164\n",
      "20          21       3.215762e+10    5011.755371\n",
      "21          22       4.414777e+10    6408.499023\n",
      "22          23       4.982550e+10    5594.157715\n",
      "23          24       5.285288e+10    5660.071289\n",
      "24          25       6.537018e+10    5913.598633\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# AGRUPAR RESULTADOS\n",
    "# =======================================\n",
    "df = pd.DataFrame(results_list)\n",
    "print(\"\\nResultados brutos:\")\n",
    "print(df)\n",
    "\n",
    "# salvar parquet\n",
    "df.to_parquet(RESULTS_DIR / \"yolov5_batchsize.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "172169fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAHZCAYAAACB9S1bAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfK1JREFUeJzt3XdcleX/x/HXQUAUFZxgmbnCvcVROXPlqBwtV5qmuchMUXMVrlQ0Qy01R5mae6SWpjb060otK1MzZ1rhBhTZ3L8/7h9HERA4Aofxfj4e53HOPc51PofLgx+u87mvy2IYhoGIiIiISA7lYO8ARERERETsSQmxiIiIiORoSohFREREJEdTQiwiIiIiOZoSYhERERHJ0ZQQi4iIiEiOpoRYRERERHI0JcQiIiIikqMpIRYREcmhtDaXiEkJschD+P333xk+fDhNmjShWrVqNG/enLFjx3Lx4kV7h5btTJ8+nSpVqnDgwIFUPW/9+vWUL1+eS5cupVNkqXfw4EHKly/PwYMH7R1KunvppZdo2rQp165dS/bctO6r7du306VLFwAuXbpE+fLlKV++PKtWrUr0/Fu3blG1atV4fRPXV/feqlSpwjPPPMO0adMICwuzPv/s2bM0a9aMkJCQNIn/fvfHUalSJZ588kmGDh3KP//8k+r2jhw5Qt++fVP1nGbNmjFy5MhUv1bc67355pvUq1ePKlWq0KRJE959990Evy8f5jVEbOVo7wBEsqrly5czefJk6tWrxzvvvEOxYsW4cOECixYt4ttvv+Xzzz+nQoUK9g4zW7h+/TorVqxg/Pjx1K9fP1XPbdKkCatWraJYsWLpFJ0k5YcffuCvv/7iyy+/pEiRIsmen5Z9df36dd5//30+/fTTePsdHBzYtm0bL7/8coLn7Nixg8jIyETbGzduHJUrVwYgLCyMkydPEhAQwNWrV5k+fToAZcqU4ZlnnmHixIlMmzbtod9DYjp37syLL74IQFRUFP/88w+ffPIJPXv2ZOvWrTg7O6e4rTVr1nDmzJl0ifN++/fvp0+fPrRo0YJJkyaRP39+/v77bxYvXkznzp1Zs2YNJUuWBGDOnDnky5cvQ+ISiaOEWMQGR44cYdKkSXTt2pXRo0db99erV4/mzZvzwgsv8O6777J+/Xo7Rpl95M6dm40bN/L444+n+rmFChWiUKFC6RCVJKdKlSps27YNDw+PFJ2fln31ySefUK1aNWsSG6dWrVocPHiQGzduJHitrVu3UrFiRU6cOJGgvXLlylGjRg3rdoMGDbh16xaffPIJ48ePtyZwffv2pUmTJrz22msJXjsteHp6xovD29sbT09PXnvtNfbt20eTJk3S/DXTwrx586hWrRqzZs2y7qtXrx6NGzemRYsWLFmyhPHjxwNQqVIlO0UpOZlKJkRssGjRIvLnz8/QoUMTHCtUqBAjR47kmWee4c6dOwDExMSwfPly2rdvT7Vq1WjSpAn+/v5ERERYnzdy5Eh69uzJunXraNWqFVWqVOH5559n9+7d1nNiY2P58MMPadasGVWqVKFZs2bMmDGDqKgoIOmv4rt370737t2t282aNWPOnDnWEe6aNWvyzjvvEBoayoIFC2jUqBG1a9dm8ODB3Lx50/q8lLyPxJQvX54vv/ySkSNHUrt2berWrcvEiRMJDw9n6tSp1K9fn3r16jF69Oh4bd24cYP333+f9u3b07ZtW+rWrcvAgQOtX6kfO3aMypUrx/t69fr16zRo0IBevXphGEaCr+FHjhxJ7969WbVqFc2bN6datWq88sornDt3ju+//5727dtTvXp1XnzxxQSJ0d69e+nSpQu1a9e2fjPw33//PfC9A6xcuZJWrVpRrVo1unXrxr///pvgnH///ZehQ4dSt25dqlevzmuvvcbx48cf2O7s2bNp3bo1O3bsoF27dlStWpXnn3+eX375haNHj/Liiy9SrVo12rVrx/79++M999SpU/Tr149atWpRq1YtBg4cGO+r67h/S/v376d79+7W/l6zZg1Xrlxh0KBB1KxZk8aNG/PZZ5/Fa/vKlSuMGjWKTp060aJFCzp37syuXbvinVO+fHnmzJlDx44dqVatGnPmzEm0ZGLNmjV07NiRGjVqUK1aNZ5//nm++eabB/5cbty4wdq1a2nXrl2CYy1atMDBwYEdO3bE23/z5k0OHDhA27ZtH9j2vQoUKJBgX9GiRalfvz7z589P8nlTpkyhfPny8cp/4t77xo0bU/z6cdzc3ACwWCzWfXGfnaZNm1KlSpUEn52RI0eyYcMG/vnnH8qXL2/94/327dtMmDCBhg0bUqNGDTp16sQPP/wQ7/WioqKYNm0aTz31FDVq1OD111/nwoULD4zx2rVridYrFytWjDFjxvDUU09Z991bMjF79uwEpSJxt9mzZ1ufs3PnTjp27EjVqlV56qmnmDhxovX3r0iKGCKSKrGxsUbVqlWNt956K8XPeffdd43KlSsbs2bNMv73v/8ZCxYsMKpXr268/vrrRmxsrGEYhjFixAijdu3axrPPPmts2bLF+OGHH4wOHToY1apVM4KCggzDMIx58+YZ3t7extq1a42DBw8aCxYsMCpWrGh89NFHhmEYxoEDBwwvLy/jwIED8V6/W7duRrdu3azbTZs2NWrWrGkMGjTI2Lt3rzF//nzDy8vLaNWqldG9e3fjhx9+MJYtW2ZUrFjReO+991L1PhLj5eVl1KxZ0xg7dqyxb98+Y9KkSdbXe+utt4w9e/YYs2fPNry8vIxPP/3U+nPu3Lmz0aJFC2PLli3GgQMHjM8//9yoWbOm8frrr1vb/vDDDw0vLy9j3759hmEYxoABA4y6desagYGBhmEYxrp16wwvLy/j4sWL1p9zzZo1jXbt2hk7duwwtmzZYtSpU8do3ry50aJFC2Pz5s3Gzp07jaeeespo06aN9XU2bNhgeHl5GUOHDjV++OEHY8OGDUbTpk2Nhg0bGteuXUvyvX/xxReGl5eXMWnSJGPPnj3GtGnTjMqVK8frp+vXrxsNGzY0WrZsaXz11VfGjh07jG7duhk1atQwTp8+nWTbAQEBRvXq1Y1mzZoZmzdvNnbt2mU0adLEePrpp42mTZsaq1atMnbv3m20adPGqFevnhEWFmYYhmGcPXvWqFmzptGpUyfj22+/Nb7++mujffv2xlNPPWV9L3H/lurXr28sXrzY2Ldvn9GzZ0+jYsWKRqtWrYxZs2YZ+/btMwYNGmR4eXkZv/76q2EYhnH16lWjYcOGRvPmzY0NGzYYP/zwg+Hj42OUL1/e2LRpU7x/E5UrVzYWL15sfP/998apU6cS9NWyZcuMChUqGHPnzjUOHDhgbN++3ejcubNRqVIl47///kvy5/Lll18alStXNm7fvm3dd/HiRcPLy8tYt26d0bdvX6Nnz54JntO8efMEn6G47X379hlRUVFGVFSUcefOHePIkSNG06ZNjZEjRyZ4/dWrVyd4/XuFhYUZLVu2NFq2bGlEREQY//zzj1GrVq1kf6d4eXkZs2bNssYRERFhnD171ujdu7fRunVrIyIiwjCMlH12Lly4YLzxxhvGU089Zfzyyy/G9evXjejoaOPFF180vL29jS+++MLYu3evMWzYMKNSpUrGoUOHDMMwf3dUqFDB6NOnj7F7925j/fr1hre3t9GhQ4cHxj5t2jTDy8vL6Natm7FmzRrj77//TvLcpk2bGiNGjDAMwzD+++8/45dffol3e/XVV42aNWtaPxtfffWV4eXlZbzzzjvGjz/+aKxYscLw9vY2XnvttQf+XhK5lxJikVS6fv264eXlZUyfPj1F5//111+Gl5eXMX/+/Hj7N27caHh5eRk//PCDYRhmoubl5WVcuHDBes5PP/1keHl5Gdu2bTMMwzBef/11o1evXvHa+eKLL4yNGzcahpG6hLhhw4ZGVFSUdV/r1q2NmjVrGiEhIdZ9/fr1M5577rlUvY/EeHl5GS+++KJ1Ozo62qhRo4bRrFmzeDG0a9fO6N+/v2EYhhEYGGh0797d+h9xnAkTJhhVqlSxbkdGRhrt27c3WrVqZU2ovvnmG+vxxBJiLy+veInmuHHj4iXVhmEYixYtMry8vIzg4GAjJibGeOqpp+Il4oZhJhWVK1c2pk6dmuj7jo2NNRo0aGAMGTIk3v6414vrp5kzZxpVq1Y1Ll26ZD0nIiLCeOaZZ4zBgwcn2rZhmAmxl5eX8eOPP1r3xf1xs2bNGuu+bdu2GV5eXsbx48cNwzCMoUOHGk8++aRx69Yt6zk3b940ateubXzwwQeGYdz9t3Tvv/OjR48aXl5exvDhw637bty4YXh5eRlLliwxDMOwJvz3vhfDMIzXXnvNeOqpp4yYmBjDMMx/E6+99lq8c+7vqylTpiT4nB07dszw8vIytmzZkuTP5a233rL+u41zb0K8YcMGo2LFisb169etx7t162bMnDkzyYQ4sVuzZs2sf3jd68SJE8l+Jn7++WejQoUKxuzZs41evXoZjRo1sv7hm5Sk4qhSpYqxf/9+63kp/eyMGDHCaNq0qXX7u+++M7y8vIwdO3ZY98XExBgvv/yyMXv2bMMwzN8djRs3NiIjI63nxP1Reu+/p/tFREQYY8eONSpWrGiNu1GjRsbYsWONM2fOxDv33oT4fkuWLDHKly9vjTE2NtZo1KiR0bt373jn7du3z/Dy8jK+//77JGMSuZdKJkRSKVeuXIBZPpASP/30E0CCr2Lbtm1Lrly54pU3FCpUyHphCZj1goD1SvZ69epZv7ZfuHAhp0+fplu3bjz//POpfh/VqlXD0fHuZQRFihShdOnS5M+f37rP3d2dW7dupfp9JKZmzZrWx7ly5aJgwYJUrlw5Xgz3vp6HhwdLly6ldu3aXLp0ib179/LFF1/w888/x7vwycnJialTp3Lp0iVGjx5Nhw4daN269QNjcXNzo2zZsvHeO0D16tXjxQIQEhLCuXPnuHr1aoKv4EuWLEnNmjWtP5v7nT17luvXr9O0adN4+5999tl42/v376dixYp4eHgQHR1NdHQ0Dg4ONGrUiH379j3wvYBZF5vS9wJw4MAB6tati4uLi/X18uXLR506dRK83r39Vrhw4QRtFyxYECDev5OaNWvy6KOPxmvnueee4+rVq5w9e9a6r2LFig98XyNHjmTYsGGEhIRw9OhRNm3axPLlywGSvPgN4OLFi5QoUSLJ482bNydXrlzWsokrV65w+PDhREss4rz//vusXbuWtWvXsmLFCqZOnUru3Lnp3LlzghKYuPf+oNkyatasSc+ePZk7dy779u3jgw8+sJY+PMhLL71kjWP16tXMnTuXJ598kj59+vDjjz8CKf/s3O/IkSM4OTnRrFkz6z4HBwdWrlzJoEGDrPuqVauGk5OTdTvuZ/2g2TWcnZ3x8/Pjxx9/ZNKkSbRv357Y2FhWrVrFc889x7fffpvse9+zZw/Tpk1jwIABNG/eHDA/Y4GBgTRr1sz6bzk6Ohpvb2/y5cvH3r17k21XBHRRnUiqubm54erqmmgdaJw7d+4QFRWFm5sbwcHBgFlbeC9HR0cKFixoTSQA8uTJE++cuJrA2NhYAPr06YOrqyvr1q3D39+f6dOn88QTTzBmzJhUz76Q2FXcefPmTfL81LyPtHg9gK+++oqZM2fy33//4e7uTsWKFXFxcUlwXsWKFSlfvjzHjh1LkHymNJYHxRMUFASQ6EwJRYoUSbLWN+5nFpc0xrn/ZxgUFMSFCxeSvAgrLCwswb+NeyX2fh50flBQEF9//TVff/11gmP3X2iW2raDg4N57LHHEuyP+9ndmzQl1/9///0348aNY//+/Tg5OVGmTBnrzC3GA+bPvX37drI/r0aNGllnm9i2bRvlypXjiSeeSPIPu9KlS1O1alXrdlwtfPPmzVm8eDFjxoyxHot77du3bz/w/XXo0IHFixdTtGjReH9kPEixYsXixQHQtGlT2rZti7+/P40bNwZS/tm5V1BQEO7u7jg4PHis7P5+izs/7vfUgxQtWpTOnTvTuXNnwPzjbPjw4bz33ns0b948ydc+e/YsQ4cOpVGjRgwePDhezGD+wfL+++8neN6VK1eSjUkElBCL2OTpp5/m4MGDREREkDt37gTHV69ezdSpU1m7dq111Ofq1avxRs2ioqK4efNmgmTpQRwcHOjatStdu3bl+vXr/Pjjj8ybN4/Bgwezd+/eBAl0nNDQUFxdXW15q1Zp+T5S4vDhw4wYMYLu3bvTu3dv60wF06ZN48iRI/HOXbVqFceOHaNChQpMmjSJBg0aJHrBk63iRlgTm0v36tWrSb73uP3Xr1+Ptz/uP/E4+fPnp27duvj6+ibaTmqm0kqJ/Pnz8+STT9KrV68Ex+4dsbeFm5sbV69eTbA/bl9K/53ExsbSt29fnJycWLt2LRUrVsTR0ZHTp0+zadOmBz43JX+gtWnThuHDh3Pjxg2+/vrrVF1MF+eRRx6hUKFCnD9/Pt7+uKT/Qe81NjaW9957j5IlS3Lt2jWmT59unWUhtXLlykWlSpXYuXMnkLrPzr3y589PUFAQhmHEu0Dv+PHjGIZh86wZv/76K/3792f69OnxLp4DqF+/Pr1792bKlCncvHnT+i3EvYKDg+nfvz9FihTB398/Xmxxn3NfX1/q1q2b4LkpGXUXAc0yIWKT119/naCgoHhTCMW5evUqixcvply5clSuXNn6S3rr1q3xztu6dSsxMTHUrl07xa/7yiuvMHHiRMD8+rpjx4507dqVkJAQbt++bR3NCwwMtD4nODg4TeYaTcv3kRK//PILsbGxDB482PofekxMjPUr/bik/59//mHq1Kl07tyZefPmcevWLSZNmpSmsZQuXZqiRYuyZcuWePsvXrzI0aNH45Us3KtUqVIUL16cbdu2xdv//fffx9uuW7cu586ds45Cxt02bdrE2rVrrWU6aaVu3bqcPn2aihUrWl+rSpUqfPbZZwlmX0gtb29vfvnllwQLRXz11VcULVo0xVPn3bx5k3PnztG5c2eqVq1qTdTjZl150GjkI488kuzsH02bNsXZ2Zlly5Zx9OhRmxLiS5cucePGDUqVKhVvf9zn75FHHknyuZ9//jk///wzkydP5q233uLLL79MMBNISkVFRXH8+HHrzzaln537R2Pr1KlDVFRUvJltDMNg1KhRD5w1IzmlSpUiLCyMpUuXJtpv586do2jRoolOuRcdHc2QIUO4du0ac+fOTfCNRZkyZShcuDCXLl2K99nx8PBgxowZyc7UIhJHI8QiNqhRowZvvfUWs2bN4syZM7zwwgsULFiQv/76i0WLFhEREWFNlsuVK0eHDh0ICAggLCwMb29vTpw4wZw5c6hXrx4NGzZM8et6e3uzePFiihQpQs2aNbl8+TJLliyhbt26FCpUCDc3N4oXL279j8NisTB//vwHfn2cUmn5PlKiWrVqAPj5+dGpUyeCg4NZvnw5J0+eBMyyFFdXV0aPHk2ePHnw9fXFzc2NIUOGMHnyZFq1ahWvFvJhODg4MHToUEaNGsU777zDc889x82bN5kzZw5ubm6JjrSCWfIybNgw3nnnHcaMGUPr1q05evQoX375ZbzzevbsyaZNm+jZsyevv/46BQsW5Ouvv2b16tWMGjUqTd7DvQYMGMArr7xCv379ePXVV8mdOzerVq1i586dBAQEPFTbvXr14quvvqJnz54MGjQId3d3Nm7cyIEDB5g8eXKyX8fHKVy4MI8++ijLly/H09OTAgUKsGfPHpYuXQoQb4W4+z311FN888033Lp1K15N/L3y5s1L48aNWbBgAdWqVUu0zONep0+ftn4bZBgG//77L3PnziV37tx069Yt3rlHjhwhT5481KlTJ9G2zp07x6xZs3jppZfw9vamVq1abN68mdGjR7N58+YHfpsTGBjI0aNHrdvBwcGsWLGCc+fO4e/vD6Tss5MvXz4KFCjAtWvX+PHHH6lYsSJNmjShZs2ajBw5kiFDhvDYY4+xadMmzpw5w4QJEx7483kQNzc3RowYwfjx4+nSpQsvvfQSjz32GLdu3WLHjh1s2LAhwchvnA8++IB9+/YxcuRIQkND4733fPnyUa5cOd5++23GjRtHrly5aNq0KSEhIXz88cdcvnw5XeaCluxJCbGIjfr370+lSpWsK9YFBwdTvHhxmjRpwptvvknx4sWt506aNInHH3+cdevW8emnn1KsWDF69OjBgAEDUpwgALz11ls4Ozuzbt065s6dS/78+WnWrBnvvPMOYH51GhAQwOTJkxk6dChFihThtdde4+zZs5w7d+6h33NavY+UqFevHuPGjWPJkiVs27aNIkWKUK9ePebMmcPAgQM5cuQIly5dYv/+/cyaNcv61Wj37t3ZvHkz48aNS3Lk1hYdO3bE1dWV+fPnM3DgQPLly0fDhg0ZOnRogprge7Vr1w4HBwc+/vhjNm3ahJeXF35+fvHmsPbw8GDlypXMmDGD9957j4iICEqVKsWkSZOstZZpqUKFCixfvpwPP/wQX19fDMPAy8uLuXPn8swzzzxU20WLFuXLL79kxowZTJw4kaioKCpUqMDHH3+c6rY//vhjJk2axMiRI3F2dqZcuXJ88sknTJ48mcOHD8ebW/teTZs2xdHRkT179tCmTZsk22/Tpg3btm174Dlx/Pz8rI8dHBxwd3enRo0aTJ8+PcEI8e7du2nSpEmiNbuxsbGMGjWK/PnzM3z4cMD83E6YMIHOnTszderUeK91v7gL6sD8g8vV1RUvLy9mzZplvVgzJZ+dxo0b07FjR3788UcGDhyIj48Pffv25dNPP8Xf35+PPvqIsLAwypcvz+LFi61Jtq1eeeUVHn/8cZYuXcrMmTMJCgrC1dWVatWq8fnnn1OvXr1En/fdd98BZmJ8v7p16/LFF1/w4osv4urqysKFC1m1ahV58+alVq1a+Pv7J/uHjkgci/GgKxNERESyoAkTJvDXX39ZR5Qzyj///EOLFi1Yu3atVlwTyUJUQywiItnOm2++ycmTJ/ntt98y9HUXL15M69atlQyLZDEaIRYRkWzp66+/ZunSpaxcuTJDXu/MmTP06dOHDRs2WGcmEZGsQQmxiIiIiORoKpkQERERkRxNCbGIiIiI5GhKiEVEREQkR9M8xDb45ZdfMAwDJycne4ciIiIiIomIiorCYrFQs2bNZM/VCLENDMPg/msRDcMgMjIywX7JutSn2ZP6NftRn2Y/6tPsKaP7NbF8LSkaIbZB3Mhw1apVrfvu3LnDiRMnKFeuHHnz5rVXaJKG1KfZk/o1+1GfZj/q0+wpo/v1999/T/G5GiEWERERkRxNCbGIiIiI5GhKiEVEREQkR1NCLCIiIiI5mhJiEREREcnRlBCLiIiISI6mhFhEREREcjQlxCIiIiKSoykhFhEREZEcTQmxiIiIiORoSohFREREJEdTQiwiIiKSFkJDITISrlwx70ND7R2RpJASYhEREZGHFR4O06aBh8fd27Rp5n7J9BztHYCIiIhIlhYaaia/fn539wUF3d329QVXV7uEJimjEWIRERGRh+HkBAEBiR8LCDCPS6amhFhERETkYQQFmbekjgUHZ2AwYgslxCIiIiIPw93dvCV1zM0tA4MRWyghFhEREXkYUVHg45P4MR8f87hkarqoTkRERORhuLrCqFFgGDB7tlkm4e4OgwbBiBGQN6+9I5RkaIRYRERE5GG5uECjRnDpEvz7L/zzD9SqBVOm2DsySQElxCIiIiIP659/oEULKF0acueGY8egY0f44AM4f97e0UkylBCLiIiIPKxvvjHvy5aFQoWgbl1o3hyio2HyZPvGJslSQiwiIiLysL7+2rxv0+buvvHjzfslS+DChYyPSVJMCbGIiIjIw4iMhB07zMf3JsRPPw3PPGOOEquWOFNTQiwiIiLyMPbsgdu3wcMDataMfyxulHjxYvj774yPTVJECbGIiIjIw4grl3j2WXC4L7Vq2BCaNjXnItYocaalhFhERETkYSRWP3yvuFHiRYvg4sWMiUlSRQmxiIiIiK3OnoWTJyFXLmjZMvFzGjc2b1FR5jRskukoIRYRERGxVdx0a08/DW5uSZ/33nvm/cKF5uIdkqkoIRYRERGxVXLlEnGaNDFXsouMhKlT0z0sSR0lxCIiIiK2CAuD774zHyeXEMPdWuIFC8yV7STTUEIsIiIiYovvv4fwcHjsMahcOfnzmzY1Sys0SpzpKCEWERERscW95RIWS/LnWyzxR4n//Tf9YpNUUUIsIiIiklqGAVu3mo9TUi4R55ln4MknISICpk1Ln9gk1TJFQrxx40batGlD1apVadu2Ld/EXbEJXLp0iX79+lGrVi2efvppZs2aRUxMTLznL1++nGeeeYZq1arRpUsXjh8/Hu94StoQERERSbE//4Tz58HZ2UxyU8piuTvjxPz58N9/6RGdpJLdE+JNmzYxevRounbtytatW2nXrh1Dhw7ll19+ISoqit69ewOwcuVK3nvvPb788kvmzp1rff6GDRuYNm0ab731FuvXr6dEiRL06tWLGzduAKSoDREREZFUiSuXaNIEXF1T99zmzaFBA7P+ePr0NA9NUs+uCbFhGHz00Uf06NGDrl27UrJkSfr378+TTz7JTz/9xPbt2/n333+ZNm0aXl5eNG/enKFDh/L5558TGRkJwLx58+jWrRvPPfcc5cqVY/LkyeTJk4c1a9YApKgNERERkVRJ6XRribm3lviTTyAwMO3iEpvYNSE+d+4c//zzD+3bt4+3f9GiRfTr14/Dhw9TuXJl3O6Z6Lp+/frcvn2bEydOcP36dc6fP0+DBg2sxx0dHalTpw6HDh0CSLYNERERkVS5dQt27zYf25IQg7mqXb16GiXOJBzt+eLnzp0D4M6dO/Tu3Zvjx49TokQJ+vfvT7NmzQgMDMTT0zPec4oVKwbAf//9h6OjGX7x4sUTnHPy5EmAZNuoXr26TbEbhsGdO3es22FhYfHuJetTn2ZP6tfsR32a/WT2Ps21dSu5o6KILVuW8EcfhXvygdRwGDECl44dMT75hLBBg8DDI40jzVwyul8Nw8CSktk/sHNCfPv2bQBGjBjBoEGDGDZsGNu3b2fAgAEsWbKE8PBwChQoEO85uXPnBiAiIsL6A3V2dk5wTkREBECybdgqKioq0RHm8+fP29ymZE7q0+xJ/Zr9qE+zn8zapyVXraIocNXbm0sP823zY49RoVIlXI8fJ2T8eP556600izEzcnR0xMXFhUuXLhEdHZ0hr3l/jpgUuybETk5OAPTu3ZsOHToAULFiRY4fP86SJUtwcXFJUOcbl8TmzZsXFxcXgETPyZMnD0CybTxM7OXKlbNuh4WFcf78eUqVKmV9bcna1KfZk/o1+1GfZj+Zuk8NA5eDBwFwe+UV8les+FDNOUyYAJ064bFuHQX8/OD/v8XOTiwWC87R0Tg4OxN78yYOBQsSGxFBpJMThmGk2+uePn06xefaNSH2+P+vBry8vOLtL1euHD/88AN169bl1KlT8Y5duXLF+ty4UokrV65QtmzZeOfEte3p6fnANmxlsVgSTajz5MnzUIm2ZD7q0+xJ/Zr9qE+zn0zZp7/+ak6VljcvLq1awf8PztmsQweoUwfL4cPk/fjj7Dk3cXg4+PtDQAC5goLA3Z1cPj7kGTUK0vEPnpSWS4CdL6qrXLkyrq6u/Prrr/H2nzp1ipIlS+Lt7c3x48etpRUABw4cwNXVlQoVKlC4cGFKly7Nwf//Sw0gOjqaw4cP4+3tDZBsGyIiIiIpFje7xDPPPHwyDPFnnJg7F65effg2M5PQUJgyBfz8ICjI3BcUZG5PmWIezwTsmhC7uLjQp08f5s6dy5YtW/j777/55JNP2Lt3L7169aJ58+YULVqUIUOGcPLkSXbu3MnMmTN5/fXXrTUhr7/+OkuWLGHDhg2cPn2ad999l/DwcDp37gyQojZEREREUuRhpltLStu2ULu2eXHejBlp125m4OQEAQGJHwsIMI9nAnYtmQAYMGAAefLk4cMPP+Ty5cuULVuW2bNnU69ePQAWLlzI+++/z0svvYSbmxtdunRhwIAB1ue/9NJL3Lp1i1mzZhEUFESVKlVYsmQJhQoVAswL6JJrQ0RERCRZN2/Cvn3m42efTbt2LRYYNw6efx7mzIFhw6BIkbRr356Cgu6ODCd2LDgYihbNwIASZ/eEGKBXr1706tUr0WOPP/44ixcvfuDze/fubV2NztY2RERERB5o+3aIjYXKleHxx9O27fbtoWZN+OUXmDkTJk9O2/btYdcuqF8f3N0TT4rd3eGedSLsye5LN4uIiIhkCelRLhHn3lri2bPh+vW0f42MEhgIr75qLlG9cycMGpT4eT4+EBWVsbElQQmxiIiISHJiY+Gbb8zHbdumz2s89xzUqAG3b5ujxFlNbCwsWAAVK8LKleDgACdOwLvvmiUh7u7mee7u5vaoUeDqas+IrZQQi4iIiCTn8GG4dg0KFIAnn0yf14irJQZzlPjGjfR5nfRw7Bg0bAj9+pnlEbVqwU8/wciR5tRqvr4Yly8TExiIcfky+PqmzSwdaUQJsYiIiEhy4solWrZM35kRnn8eqlWDW7fgww/T73XSSlgYjB5t1j/v22eO+H74IRw8aM6cEcfVlbDoaE5eu0ZYdHSmGRmOo4RYREREJDnpWT98LweHu6PEAQHmzBaZ1Y4dULWqeQFgdLRZ8nHiBAwZAo6Jz9sQHh6esTGmkBJiERERkQe5fBkOHTIft26d/q/XoQNUqQIhITBrVvq/XmpduQLdupmj5WfOwKOPwvr1sGkTPPaYvaOziRJiERERkQfZts28r1ULihdP/9dzcLg748RHHyU9j29Gi42FRYugQgVYvtysefbxgePHzSQ+C1NCLCIiIvIgGVUuca+OHc1R4uDgzDFKfOIENGkCffqYZRw1aph1wh99ZF5omMUpIRYRERFJSnS0uSAHpN90a4lxcICxY83Hs2bZb5Q4PNysaa5eHfbsgbx5wd/fLCHx9rZPTOlACbGIiIhIUvbvN0dpCxfO+ASwc2eoVMl8/YCA9H2t0FCIjDTrgyMjze0DB8wZLyZMMBfQaNvWLI94550kL5rLqpQQi4iIiCQlrlyidWvIlStjX/veUeIPPzQT4/QQHg7TpoGHx93b1KlQtqz5nj09YfVq2Lw57ZesziSUEIuIiIgkxR71w/d68UXzIragIHOxjrQWGgpTpoCf392yjKAgc1Q4IACWLYOTJ804LJa0f/1MQgmxiIiISGIuXoTffjMTwVat7BNDrlx35yWeOdNcsONhhYeb72vjRnMUOqlyjDlzzHmG3dwe/jUzuexVACIiIiKSVr75xryvX9+sIbaXl14yR2r79jVrd69cAXd3s673QSu+hYaao7vHj5u3EyfM+zNnzCnUqlQxL5ZL6oK9oCCzTKNo0XR4U5mLEmIRERGRxMSVS2Tk7BKJyZULVq4063x79jQTVXd3cw7gUaPMi+D++ONuwht3u3Ah6Tbd3KBkSbM+2N098aTY3T1HjA6DEmIRERGRhCIiYOdO87G96ofjhIaaU51NnHh3X1CQWfcbGwu1aye9MEbRouZMFXG3ihXNe09PsxQkNNRMrP38Ej7Xx8cchXZ2Tpe3lZkoIRYRERG53549ZrJYvLi5CIU9OTk9uM730iWz1tfT827CG5f8Finy4LZdXc1RZjBf4/7RZxeXtHwnmZYSYhEREZH7xZVLPPus/WdXCAp6cJ1vaKh5kZytXFzA1xdGjzZrht3czJHhHJIMgxJiERERkYTsPd3avdzdH1zn6+7+8K8Rd3Fe3AV0OaBM4l6adk1ERETkXmfOwJ9/mjM6NG9u72jM0Vofn8SPxdX5ykPRCLGIiIjIveJGh59+OnPMsqA633SnhFhERETkXpllurV7qc43XSkhFhEREYlz5w58/735ODPUD98rh9f5pifVEIuIiIjE+f57cw7ixx83py2THEEJsYiIiEice2eXsPd0a5JhlBCLiIiIABhG5ppuTTKMEmIRERERgBMn4Px5yJ0bmja1dzSSgZQQi4iIiMDd0eEmTe5ewCY5ghJiEREREcic061JhlBCLCIiIhISAnv2mI+ffda+sUiGU0IsIiIisnMnREeDlxeUK2fvaCSDKSEWERER0ewSOZoSYhEREcnZNN1ajqeEWERERHK2o0fhv//MmSUaNbJ3NGIHSohFREQkZ4sbHW7e3JyDWHIcJcQiIiKSs6lcIsdTQiwiIiI51/XrcOCA+VjTreVYSohFREQk5/r2W4iNhapV4bHH7B2N2IkSYhEREcm5VC4hKCEWERGRnComBrZtMx8rIc7RlBCLiIhIznToEFy7Bm5u0KCBvaMRO1JCLCIiIjlTXLlEq1bg5GTfWMSulBCLiIhIzqT6Yfl/SohFREQk5wkMhCNHzMetW9s3FrE7JcQiIiKS88RdTFenDnh42DcWsTslxCIiIpLzqFxC7pEpEuLLly9Tvnz5BLf169cDcOLECbp160aNGjVo1qwZS5cujff82NhYAgICaNiwITVq1OCNN97g4sWL8c5Jrg0RERHJIaKi4NIlKFJECbEA4GjvAABOnjxJ7ty52blzJxaLxbo/f/783Lx5k169etGsWTPef/99jh49yvvvv4+rqyudOnUC4OOPP2bFihV88MEHeHp6Mn36dPr06cPmzZtxdnZOURsiIiKSA4SGgqMjLF8OxYqBYdg7IskEMsUI8alTpyhVqhTFihWjaNGi1puLiwurV6/GyckJPz8/ypYtS6dOnejZsycLFiwAIDIyksWLF+Pj40OTJk2oUKECH374IYGBgXz77bcAybYhIiIiOUB4OEybBp6eUKYMlCgB06eb+yVHyxQJ8Z9//knZsmUTPXb48GHq1q2Lo+Pdwez69etz/vx5rl27xsmTJwkNDaXBPRNqFyhQgEqVKnHo0KEUtSEiIiLZXGgoTJkCfn4QFGTuCwoyt6dMMY9LjpUpSiZOnTpFwYIF6dq1K+fOnePxxx+nf//+NGrUiMDAQLy8vOKdX6xYMQD+++8/AgMDAShevHiCc+KOJddGkSJFUh2zYRjcuXPHuh0WFhbvXrI+9Wn2pH7NftSn2U969GkeR0csAQGJHwwIwBg9mrB7/l+XtJfRn1XDMOKV4j6I3RPi6Ohozp49S7ly5Rg5ciT58uVj69at9O3blyVLlhAeHo6zs3O85+TOnRuAiIgI6w81sXOCg4MBkm3DFlFRUZw4cSLB/vPnz9vUnmRe6tPsSf2a/ahPs5+06FOHsDCK79tHnpdeujsyfL+gIGJv3uTctWuEq3wi3WXkZ/X+/C8pdk+IHR0dOXjwILly5cLFxQWAKlWq8Ndff7Fo0SJcXFyIjIyM95y4JDZv3rzW50RGRlofx52TJ08egGTbsIWTkxPlypWzboeFhXH+/HlKlSplfV3J2tSn2ZP6NftRn2Y/adKnwcE4zp+P05w55ijhwIHg7p54UuzujkPBgpTOn/9hwpZkZPRn9fTp0yk+1+4JMYCrq2uCfU888QT/+9//8PT05MqVK/GOxW17eHgQHR1t3VeyZMl455QvXx4g2TZsYbFYEk2m8+TJY3OSLZmT+jR7Ur9mP+rT7MemPr1+HT76CAIC4P+/KaZsWfj3X/DxMWuG7+fjgyUqiryJ5COS9jLqs5rScgnIBBfV/fXXX9SqVYuDBw/G23/s2DHKlSuHt7c3R44cISYmxnrswIEDlC5dmsKFC1OhQgXy5csX7/khISEcP34cb29vgGTbEBERkSwuMBB8feHxx2HCBDMZrlTJnF7t5El44gkYNQrGjTNHisG8HzfO3K9kOEeze0JctmxZypQpg5+fH4cPH+bMmTNMmTKFo0eP0r9/fzp16sTt27cZPXo0p0+fZv369Xz22Wf069cPMGtDunXrhr+/P7t27eLkyZO8/fbbeHp60rJlS4Bk2xAREZEs6uJFGDwYSpc2p1ALDYWaNWHdOvj9d+jSxZx3GMDFxUyaL1+GK1fMe19fc7/kaHYvmXBwcGDevHnMmDGDIUOGEBISQqVKlViyZIl1ZoiFCxcyadIkOnToQNGiRfH19aVDhw7WNnx8fIiOjmbMmDGEh4fj7e3NokWLcHJyAqBw4cLJtiEiIiJZyJkz8MEH8Pnn5spzAPXrw9ix8OyzkNTX5XEjwUWLmvcpvOhKsje7J8QARYoUYcqUKUker1atGqtWrUryeK5cuRg+fDjDhw+3uQ0RERHJPFySGrU9cQImT4YVKyA21tzXtCmMGWPep6JuVCROpkiIRURERAAIDSWPkxMVChfGwdHRLIFwdYWjR2HSJLMUIm655WefhdGj4amn7BqyZH12ryEWERERAaxLK1s8PMhVvDgWDw9zqeUbN+DVV2HtWjMZ7tABDh+Gr79WMixpQiPEIiIiYn+hoWbye++0aHFLK8fGmssrr14N774LVarYLUzJnpQQi4iIiP05OZlzBydmzhxzWrUXXsjQkCTnUMmEiIiI2F9Q0AOXViYkJAODkZxGCbGIiIjYV0wM5M9/d8GM+7m7g5tbRkYkOYwSYhEREbGfS5fgmWfg229h0KDEz/HxuTvXsEg6UA2xiIiI2MfGjdC7tzmLxO3b8P334OBg1hIHBZkjwz4+5tLKWk1O0pESYhEREclYYWEwbBh8/LG5Xbs2fPmlWTbh64sxejSxN2/iULAglqgoJcOS7lQyISIiIhnn2DGoW/duMjx8OOzbB088YW67uhIWHc3Ja9cIi46+u9SySDrSCLGIiIikP8OA+fPh7bfNBTg8PGDpUmjZMtHTw8PDMzhAycmUEIuIiEj6unHDrBXeuNHcbt0aPv8cihWza1gicVQyISIiIunnxx+henUzGXZygpkzYetWJcOSqSghFhERsYfQUIiMhCtXzPvQUHtHlLaio2HcOGjWzJxazcsLDhwwSyYclH5I5qJ/kSIiIhktPBymTTPraONu06aZ+7OD8+ehcWOYMAFiY6FXLzhyBGrVsndkIolSDbGIiEhGCg01k18/v7v7goLubvv6Zu2ZFVavhr59ITgYChQwL6R75RV7RyXyQBohFhERyUhOTubCE4kJCDCPZ0WhodCnD7z8spkM168PR48qGZYsQQmxiIhIRgoKMm9JHQsOzsBgbHR//XNgILz4IixaBBYLjB4Nu3dD6dL2jlQkRZQQi4iIZKQCBcwliRPj7g5ubhkZTeolVv88d645jVqjRrBrF0ycmHVHuiVHUg2xiIhIRvn4YyhRAgYNMpPG+w0aZM7IUKZMxseWEknVP0+caI4Mb9qUdLIvkolphFhERCS9RUXBwIHmbcQIGDrUnJIsLnl0d4exY8HHB9q1A39/c2W3zOZB9c+zZ0PevBkbj0gaUUIsIiKSnm7cgGefNUeHLRZ47TUzAfb1hcuXzTrcy5fN7Xnz4MQJGD4c+vc35/LNTLJD/bNIIpQQi4iIpJeTJ6FePbOu1tUVNmyAkSPNxNjVFZydoWhR8z5fPhgzBj780Dw+fz60bw8hIfZ+F6bffjNjzsr1zyJJSHVCfOfOHe7cuWPdDgwMZNKkSfTt25fJkyfz999/p2mAIiIiWdK335pTj50+DSVLwr598PzzD36OxQJDhsD69ZAnD2zbBg0bwsWLGRJyomJiYMoUqF0bdu4065wT4+NjloaIZEEpTojDw8MZMWIE3t7eeHt7M2bMGK5cucJLL73EihUrOH78OMuXL+eFF17gxIkT6RmziIhI5mUYZp3ts8+aJQRPPQWHDkG1ailv44UXzGnLPDzMkdl69eDnn9Mt5CSdPw9NmsC775rlG999Zz6+v/553DgYNSprLygiOVqKE+LZs2fz7bff8uabbzJ8+HD2799P165dKVCgADt37uR///sf27dvp3jx4sydOzc9YxYREcmcIiOhXz946y1zyeLXXjPLJYoVS31bderAwYNQuTL89585pdmWLWkfc2IMA5YuNZP4//0P8ueHzz6DWbPMkevE6p9dXDImNpF0kOKEePv27bz11lsMHjyYnj17Mn36dC5evMgbb7xB8eLFAShRogQDBgzgl19+SbeARUREMqXr16FlS/j0U7P0Yfp0WLIEcue2vc3HH4e9e6FFC3PKs+efN2dzSE83bpirzb32Gty6ZY5w//qruW2xmOfcX/+skWHJ4lKcEAcGBlKxYkXrdqVKlQAoWbJkvPMeffRRgpK6AlVERCQ7+uMPqFsXfvzRHE3dvBmGDbubQD4MNzfYutVcFjk21qzVHTLErO1Nazt2QNWqsGYNODrCpEnme9KKc5LNpTghjo6OJk+ePNZtp/9fgcbZ2TneeRaLhdjY2DQKT0REJJPbuhUaNICzZ83Ecf9+aNs2bV/DyQkWLDAvbgP46CPo2NEcNU4LYWFmkt2yJfz7L5Qvb76Pd9+FXLnS5jVEMjFNuyYiImILw4AZM8yp0W7dMmt8f/rJrPlNDxaLOWXbqlVmGcZXX0HjxmZ98cP49Vfw9jaTbIABA8wL+OrUefiYRbKIVC3dfPz4cSIiIgCIiYnBYrFw/PjxeNOw/fXXX2kboYiISGYTEWEunLFkibndpw/MnWvW06a3l14yl39+/nk4csSc2m3rVqhSJXXtxMTAzJkwerQ5XZqHByxeDG3apE/cIplYqhLi999/P962YRiMHTsWyz01UoZhxNsWERHJVq5cgU6dzNkXHBzMpNLHJ23qhVPqySfhwAEzeT11yrzwbc0as+QhJf7+G3r0MOuDwUyuP/3UvEhOJAdKcUK8dOnS9IxDREQk8/v9d7NE4sIFKFDALF9o3do+sZQta9b5duhgzlncpg188gm88caDn7dihVkWERxszg4xaxb07p2xCb1IJpPihLhu3brpGYeIiEjmExpqXtAWFGQmwOfPm/Pwlitn1vDeM/uSXRQqZK6I98Yb8MUX0LcvnDkDkyebF8rFxe7ubm5PmGDWPYO52MeyZeZ7EcnhUpwQHzp0KFUNe3t7pzoYERGRTCM8HKZNM1edi0sqBw0y5wV2cLi7Upu95c4Nn39ujhi/9x5s2gQjRpgjv/fHPmKEuRz0iy+atcOOqaqcFMm2UvxJ6N69e4Ja4TiJ1RBr+WYREcmyQkPNZNjP7+6+oCCYONFMhn197RZaoiwWGD8eypQx5y2eOdOMNU5c7GCOKD/yiF3CFMmsUpwQOzk5ERUVRaVKlWjbti1Vq1ZNz7hERETsx8nJHF1NTECAObqaGXXvbo5sv/Za4sfnzIGxYzM2JpEsIMUJ8f79+9mxYwdbt27lww8/5NFHH6VNmza0a9eOsmXLpmeMIiIiGSsoyLwldSw4OPPOyBASknVjF7GTFCfE+fLlo0OHDnTo0IGgoCC2bdvG119/zfz58ylXrhzt2rWjTZs2lChRIj3jFRERSX/u7uYtscTS3d0sS8issnLsInZi00p17u7uvPLKKyxdupQffviBzp078/3339OyZUteeeUVvvjii7SOU0REJOP8/rt5EVpifHzMhSwyq6goM8bEZPbYRezkoS8vLVasGD169KB9+/YsW7aM+fPn8+uvv9K9e/e0iE9ERCRjff+9OU/v7t3mBXT3ztTg4wOjRoGLi72jTJqrqxkjZL3YRezkoRLioKAgduzYwbZt2zh48CBOTk40b96cNlr2UUREsqLbt81FKs6dM5di9vU1L6ALDjZLDaKiskZC6eKSdWMXsYNUJ8T3J8EODg40atSIadOm0bRpU/LkyZMecYqIiKS/UaPMZLhkSRg61BxthbsXoTk72y+21MrKsYtksBQnxGvWrLEmwRaLhaeeeopJkybxzDPPkC9fvvSMUUREJP39+KM5LRnAwoXmynQikiOkOCEeO3YsuXLlolatWjRv3hw3NzcMw2Dnzp2Jnv/CCy+kVYwiIiLpKzQUXn/dfPzGG9CihX3jEZEMlaqSiZiYGA4dOpTsMs4Wi0UJsYiIZB3vvgtnz8Jjj4G/v72jEZEMluKEeNeuXekZBwDnzp2jY8eOjB07lo4dOwJw4sQJJk2axLFjxyhUqBA9e/akR48e1ufExsYyZ84c1qxZw61bt/D29mbcuHE89thj1nOSa0NERHKw3bvvrkqnUgmRHCnF8xA/+uijqbqBmaz26NGD8+fPJ9t+VFQUw4YN486dO9Z9N2/epFevXpQsWZJ169YxcOBA/P39WbdunfWcjz/+mBUrVjBhwgRWrlxJbGwsffr0ITIyMsVtiIhIDnXnzt1SiT59oGVL+8YjInbx0PMQP4hhGPz000+EhoYme+7s2bMTXJy3evVqnJyc8PPzw9HRkbJly3LhwgUWLFhAp06diIyMZPHixQwbNowmTZoA8OGHH9KwYUO+/fZb2rVrl2wbIiKSg40eDWfOQIkSKpUQycFsWqkurR06dIhVq1bxwQcfxNt/+PBh6tati6Pj3by9fv36nD9/nmvXrnHy5ElCQ0Np0KCB9XiBAgWoVKmStc45uTZERCSH+t//4KOPzMeffqoljUVysHQdIU6JkJAQfH19GTNmDMWLF493LDAwEC8vr3j7ihUrBsB///1HYGAgQILnFStWzHosuTaKFCliU9yGYcQr7wgLC4t3L1mf+jR7Ur9mPzb16Z07uPTqhYNhEN2jB5GNGpnlE5Ip6HOaPWV0vxqGgcViSdG5dk+I33vvPWrWrEn79u0THAsPD8f5vonEc+fODUBERIT1B5rYOcHBwSlqw1ZRUVGcOHEiwf6U1EtL1qI+zZ7Ur9lPavq0xIcfkvf0aSKLFeN4r17EJPL7XOxPn9PsKSP79f4cMCl2TYg3btzI4cOH2bx5c6LHXVxcrBfHxYlLYvPmzYvL/y9BGRkZaX0cd07cinnJtWErJycnypUrZ90OCwvj/PnzlCpVSqv1ZRPq0+xJ/Zr9pLZPHQ4cIPeKFQDEfvIJXnXrpneIkkr6nGZPGd2vp0+fTvG5dk2I161bx/Xr160XxMUZP348X3/9NZ6enly5ciXesbhtDw8PoqOjrftKliwZ75zy5csDJNuGrSwWS6IJdZ48eR4q0ZbMR32aPalfs58U9WlYGPTvD4YBPXvi8v9TfErmpM9p9pRR/ZrScgmwc0Ls7+9PeHh4vH0tW7bEx8eH5557jk2bNrFy5UpiYmLIlSsXAAcOHKB06dIULlyY/Pnzky9fPg4ePGhNiENCQjh+/DjdunUDwNvb+4FtiIhIDjJ2LJw6BY88AjNn2jsaEckk7DrLhIeHB48//ni8G0DhwoXx8PCgU6dO3L59m9GjR3P69GnWr1/PZ599Rr9+/QCzLqRbt274+/uza9cuTp48ydtvv42npyct/38uyeTaEBGRHGLfvrtJ8IIFULCgfeMRkUzDphHiiIgI64VpD2KxWHjkkUdSXNB8v8KFC7Nw4UImTZpEhw4dKFq0KL6+vnTo0MF6jo+PD9HR0YwZM4bw8HC8vb1ZtGgRTk5OKW5DRESyubAwcwEOw4AePaBtW3tHJCKZiE0J8VNPPUXbtm3p1KkT1apVS/I8BwcHvvvuu1S1/eeff8bbrlatGqtWrUry/Fy5cjF8+HCGDx+e5DnJtSEiItnc+PHw559QvDjMmmXvaEQkk7GpZOL111/nwIEDvPzyy7Rp04aFCxdy9erVtI5NRETk4R04ADNmmI/nz1ephIgkYFNCPGDAALZv387y5cupXbs28+fPp2nTpvTt25ft27cTFRWV1nGKiIikXng49OoFsbHQrRskMue9iMhDXVRXq1YtJkyYwN69e/noo48ICwtjyJAhPP3000ydOpV//vknreIUERFJvffeg5MnwcPj7jLNIiL3eehZJv777z8WL15MQEAAhw4dolSpUnTs2JHdu3fTpk0bvv7667SIU0REJHV++gmmTzcfz58PhQrZNx4RybRsuqju9u3bbN++nY0bN3LkyBFcXFxo3bo148ePp1atWgCMGDGCfv36MXnyZNq0aZOmQYuIiDzQvaUSXbrA88/bOyIRycRsnmUiIiKCGjVq4OfnR5s2bRJdcaRq1aocP378oYMUERFJFT8/OH4cihWDgAB7RyMimZxNCfFzzz1Hr169KFOmzAPP69WrF/3797cpMBEREZscOgRTp5qP580DrUoqIsmwqYb4hx9+4OTJk8me5+rqal0uWUREJN1FRNwtlXj1VdAiTCKSAjYlxJGRkRTUPI4iIpLZTJgAf/yhUgkRSRWbSiZ69OjBrFmzcHFxoUKFCuTJkyet4xIREUkxFxcXLL//Dh98YO745BMoUsS+QYlIlmFTQrxp0yb+/fdfunTpkuhxi8Wii+lERCT9hYaSx8mJCoUL41CqFKxdC7t3Q8eO9o5MRLIQmy+qExERsavwcJg2DUtAALmCgsDdHQYNgkmT7B2ZiGQxNiXEgwYNSus4REREUi40FKZNM6dXixMUBBMngoMD+PqCq6vdwhORrMWmhBjMC+vWrVvHTz/9REhICAULFqROnTq88MILuLi4pGWMIiIi8Tk5JX3RXEAAjB6dsfGISJZmU0IcEhJCjx49OHnyJI888ghFixbl3LlzbNmyheXLl7NixQry58+f1rGKiIiYgoLMW1LHgoOhaNEMDEhEsjKbpl2bMWMGgYGBLFu2jO+++45Vq1bx3XffsWzZMq5fv85HH32U1nGKiIiYrl2DfPnMmuHEuLuDm1tGRiQiWZxNCfGuXbsYMmQIderUibe/Tp06+Pj48O2336ZJcCIiIvFs3w5VqsCOHeYFdInx8YGoqIyNS0SyNJtKJkJDQ3nssccSPfbYY48RlNTXWCIiIrYID4dRo2DWLHN74UJYudK8gC4gwCyTcHc3k+FRo0DXsohIKtg0QlymTBm+//77RI99//33PP744w8VlIiIiNUff0C9eneT4UGDYPVqcxYJX1+My5eJCQzEuHzZnF1CybCIpJJNI8S9e/fmnXfeISYmhrZt21KkSBGuXbvGli1bWL16NePHj0/rOEVEJKcxDJg7F4YPN0eIixaFJUugbdu757i6EnbnDueuXaN0/vzk1VRrImIDmxLiNm3acP78eebNm8fKlSsBMAwDZ2dnBgwYwMsvv5ymQYqISA5z5Qr06gVff21uP/usmQx7eCR6enh4eAYGJyLZjc3zEA8YMIBu3brxyy+/EBISgpubG9WrV8dNV/aKiMjD+OYb6NnTTIpz5zYX4Bg8GCwWe0cmItmUzQkxQIECBWjcuHFaxSIiIjlZeLhZAzx7trldpQqsWAFVq9o3LhHJ9mxKiP/991/8/Pz4+eefuXXrVoLjFouF48ePP3RwIiKSQ/z+O3TpAseOmds+PvDBB5Anj33jEpEcwaaEePTo0Rw9epROnTrhntTE6CIiIskxDHNE2NcXIiKgWDH47DOzZlhEJIPYlBAfPXqUiRMn0vbeK31FRERS4/Jls1Z42zZzu00b88K5YsXsGpaI5Dw2zUNctGhR8uhrLBERsdXWrWZt8LZt5rzBc+bAli1KhkXELmxKiPv168fs2bP5559/0joeERHJbkJDITLSnDUiMhKOHIFhw+DqVTMpPnwYBg7ULBIiYjc2lUw0adKEhQsX0rx5cwoWLJhgtNhisbBz5840CVBERLKw8HBz2rR7l1ceNAh27zaXX377ba0sJyJ2Z1NCPGrUKC5evMjTTz9NkSJF0jomERHJDkJDzWTYz+/uvqAgmDgRHBy0zLKIZBo2JcQ//fQT48eP58UXX0zreEREJKuLjIRffoFq1cyR4cQEBMDo0Rkbl4hIEmxKiAsUKEDx4sXTOhYREcmKYmLMBPj77+G772DPHihdGr76yhwRTkxQEAQHQ9GiGRmpiEiibEqIX331VRYsWECNGjXIly9fWsckIiKZmWHAH3+Yye9338GPPyZMfKOiwMPDrBlOLCl2dwc3t/SPVUQkBWxKiP/77z/++OMPnn76acqUKZMgKbZYLHz++edpEqCIiKSz0FBwcrp70VtUFLi63j1uGHDmzN0E+PvvzRkj7lWgADRpAs2ambfKlSEszFxx7t4a4jg+PubrODun4xsTEUkZmxLic+fOUalSJeu2YRjxjt+/LSIimVRis0D4+MCIEbBjB2zYYCbBFy/Gf16ePNCw4d0EuGZNcLzvvxRXVxg1ynx8f/ujRumCOhHJNGxKiL/44ou0jkNERDJaUrNA+PlBbCzUrg1x3/Y5OUGDBncT4Lp1IXfu5F/DxcWcTWL0aLNm2M3NHBlWMiwimYhNCXGc4OBgDh8+zJUrV2jVqhVBQUGULl0aiyZXFxHJ/Jyckp4FYs4c+Ocfc4q0unXhqacgb17bXieu/CLuAjqVSYhIJmNzQvzJJ58wf/58wsPDsVgsVKtWjVmzZnHz5k0WL15MgQIF0jJOERFJa0FBD54FIjRUU6OJSI5g09LNy5YtY/bs2fTq1YvVq1dba4a7devGxYsX+eijj9I0SBERSWOGAfnzmzW9idEsECKSg9iUEH/xxRf07duXt956i8qVK1v3N27cmCFDhvDdd9+lWYAiIpLGoqKgb1/49ltzGeXExM0CISKSA9hUMvHvv/9St27dRI+VKVOGa9euPVRQIiKSToKC4MUXYedO2LcP9u83l1HWLBAikoPZNEJcvHhxfvnll0SPHTt2TKvYiYhkRufOmRfH7dxpXug2bZo5f7CvL1y+bM4tfPmyua1kWERyEJtGiDt37szs2bNxcXGhSZMmANy5c4ft27czf/58evXqlZYxiojIwzp4EJ57zkx6H30UtmyBGjXMY5oFQkRyOJsS4jfeeINLly7h7++Pv78/AD169ACgffv29OvXL+0iFBGRh7N2LXTvbi7CUbMmbN5sJsUiIgLYmBBbLBb8/Pzo1asXBw4cIDg4mPz58+Pt7Y2Xl1daxygiIrYwDJg69e5qce3bw4oVkC+ffeMSEclkHmphjtKlS1O6dOm0ikVERNJKVBT07w+LFpnbb70FM2ZArlz2jUtEJBOyKSGOjIxk2bJl/Pzzz4SEhCQ4brFY+Dxuuc8UuH79Oh988AF79uwhIiICb29vRowYQdmyZQE4ceIEkyZN4tixYxQqVIiePXtaSzQAYmNjmTNnDmvWrOHWrVt4e3szbtw4HnvsMes5ybUhIpJtBAVBp07w3Xd3Z5AYONDeUYmIZFo2zTLh5+fHtGnTuHDhAoZhJLjFxsamqr2BAwdy4cIFFixYwNq1a3FxcaFnz56EhYVx8+ZNevXqRcmSJVm3bh0DBw7E39+fdevWWZ//8ccfs2LFCiZMmMDKlSuJjY2lT58+REZGAqSoDRGRbOHcOXjySTMZzpfPrBdWMiwi8kA2jRDv2LGDwYMHMzANfskGBwfz6KOP0q9fP2v98YABA3j++ef566+/2L9/P05OTvj5+eHo6EjZsmWtyXOnTp2IjIxk8eLFDBs2zDrjxYcffkjDhg359ttvadeuHatXr35gGyIi2cL+/fD883D1KpQoYc4kUb26vaMSEcn0bBohdnBwoGbNmmkSgJubGzNmzLAmwzdu3OCzzz7D09OTcuXKcfjwYerWrYuj493cvX79+pw/f55r165x8uRJQkNDadCggfV4gQIFqFSpEocOHQJItg0RkSxv9Wpo2tRMhmvVMqdZUzIsIpIiNo0Qv/DCC6xdu5b69evj4GBTTp2osWPHsnr1apydnfnkk0/ImzcvgYGBCWauKFasGAD//fcfgYGBAAkWAylWrJj1WHJtFClSJNWxGobBnTt3rNthYWHx7iXrU59mT9muXw0DR39/nN97D4Dotm2JXLLEnFv4nt9R2Vm261NRn2ZTGd2vhmFgsVhSdK5NCfGQIUN44YUXaNWqFZUrVyZPnjzxjlssFiZPnpzqdl977TVefvllli9fzsCBA1mxYgXh4eE43zdJfO7cuQGIiIiw/lATOyc4OBgg2TZsERUVxYkTJxLsP3/+vE3tSealPs2eskO/WqKiKDl5MkU2bwbgcpcuXHrrLfj7bztHZh/ZoU8lPvVp9pSR/Xp//pcUmxJif39/zp07R548efjtt98SHE9pNn6/cuXKATBp0iR+/fVXli1bhouLi/XiuDhxSWzevHlx+f/lRSMjI62P486JS9STa8MWTk5O1njB/Gvn/PnzlCpVKsEfCJI1qU+zp6zerxaLBcMw4OZNcnfpQq7duzEcHIiaMYP8fftS0d4B2kFW71NJSH2aPWV0v54+fTrF59qUEH/11Vf07NkTX1/fhy6ZuHHjBvv376dVq1bWGl8HBwfKlSvHlStX8PT05MqVK/GeE7ft4eFBdHS0dV/JkiXjnVO+fHmAZNuwhcViSTSZzpMnj81JtmRO6tPsKcv1a2goODmZU6q5ucHx4+YyzPnyYVm9GudnnyWnL7ic5fpUkqU+zZ4yql9TM0BrUzYbExND06ZN06R++Nq1awwdOpT9+/db90VFRXH8+HHKli2Lt7c3R44cISYmxnr8wIEDlC5dmsKFC1OhQgXy5cvHwYMHrcdDQkI4fvw43t7eAMm2ISKSqYWHw7Rp4OFh3jw9Yfdu2LMHDh2CZ5+1d4QiIlmaTRltixYt+Oabb9IkAC8vLxo1asTEiRM5dOgQp06dYuTIkYSEhNCzZ086derE7du3GT16NKdPn2b9+vV89tln9OvXDzBrQ7p164a/vz+7du3i5MmTvP3223h6etKyZUuAZNsQEcm0QkNhyhTw8zNHh8G8nzgRZs+GexYgEhER29hUMlG9enX8/f05efIkNWvWxNXVNd5xi8WSqjmKZ86cyYwZM3j77be5desWderUYfny5TzyyCMALFy4kEmTJtGhQweKFi2Kr68vHTp0sD7fx8eH6OhoxowZQ3h4ON7e3ixatAgnJycAChcunGwbIiKZkpOTudJcYgICYPTojI1HRCQbshiGYaT2SRUqVHhwoxZLojMwZBe///47AFWrVrXuu3PnDidOnKBixYqqd8om1KfZU5bp19hYsySiVCnzlpQrV6Bo0YyKKlPKMn0qKaY+zZ4yul8Ty9eSYtMI8cmTJ215moiIJCcyEr78EqZPh8uX4fx5cHe/Wy5xL3d38wI7ERF5KGm3qkYiYmJiqFixIn/88Ud6voyISNZ36xbMnAlly0LPnvDHHxARAX/9BT4+iT/HxweiojI0TBGR7MimEeLUsKEiQ0Qk57h82bw4bu7cu6PAnp4wZAi8+aY5AhxXphYQYJ7j7m4mw6NGwT3zr4uIiG3SPSEWEZFEnDkD/v6wZIk5Egzg5QXDh0P37vD/q2kCZtLr62teQBccbCbJUVFKhkVE0ogSYhGRjHTkCEydCuvWmRfOAdSrByNGwHPPQa5ciT8vbjafuAvoUrgcqYiIJE8JsYhIejMM2LHDXFxj1667+9u0MRPhhg3BxiXvRUTk4SkhFhFJC/curezubpY05M4Na9aYifDRo+Z5jo7w6qtmaUQKpgISEZH0l66zTIiI5Aj3L63s4WGWRQQFmSvMHT0KefPCW2+ZtcNLlyoZFhHJRDRCLCLyMEJDzWTYz+/uvqAgmDDBLJXw94eff4YBA6BwYbuFKSIiSVNCLCLyMB60tPKcOTB2LLRtm7ExiYhIqthUMhEZGfnA4xcvXjQbd3CgQ4cOFCxY0JaXERHJ3GJi4Nq1xFeRA3N/cHBGRiQiIjawKSHu1KkTp06dSvTYsmXLeO655wCwWCxMmTKFRx55xPYIRUQyG8OArVuhaVNzTmB398TP09LKIiJZgk0JcUxMDJ07d+azzz6z7vvnn3947bXXmDhxIg0bNkyr+EREMpdDh6BZM2jXDvbsgR9+gMGDEz9XSyuLiGQJNtUQb9y4EX9/f6ZOncqPP/5I48aNmT17Nvnz52fu3Lk888wzaR2niIh9nTljrhS3apW5nTu3OWvE00/DM8+Y8whraWURkSzJpoTY2dmZd999l/r16zNo0CAOHDhAxYoVWbZsGXnz5k3rGEVE7OfqVZg4ET75xBzttVigRw9zVomSJe+ep6WVRUSyLJvnId6wYQOjR48mX758tGjRguPHjzN48GAuXbqUlvGJiNjHnTsweTKULWuO/EZFQatW8Msv8Nln8ZNhMJdWdnY2l1Z2dr671LKIiGR6NiXEr732Gu+++y5Vq1Zl8+bNBAQEsHDhQs6ePUv79u1ZsmRJWscpIpIxYmJg0SJ44glzxPfWLahZ01x6eds2qF7d3hGKiEgasykh/uOPP5gwYQILFizAw8MDgKeffprNmzfTunVrpk2blqZBioiku7iZI6pXhz594N9/oVQpWL4cDh+G5s3tHaGIiKQTm2qIt2zZgqenZ4L9+fLlY8qUKbRu3fqhAxMRSS8u99f2/vSTWQP844/mdsGC5oIaAwaYF8+JiEi2ZlNCHJcMX79+ncjISAzDACA2NpawsDD+/ffftItQRCSthIaSx8mJCoUL4+DoaC6qMXkyfPiheTx3bhgyBEaOTHpuYRERyXZsSohPnjzJsGHDOHPmTKLHLRYLr7766kMFJiKSpsLDYdo0LAEB5IqbGm3QIHNqtG3boG7dhDNHiIhIjmBTQjxt2jSCg4MZMWIE33//Pc7OzjRt2pTdu3eze/duli5dmtZxikhOEBoKTk535/KNikqb2RpCQmDGDDPhjRMUZE6nZrHAd99BImVgIiKSM9h0Ud2vv/7KW2+9Rc+ePWnTpg1hYWF06dKFefPm0bx5c7744ou0jlNEsrv/H8HFw+Pubdo0c/+DxMZCYKBZB7xmjZn4vvUWdOgAtWtD+fKQK5c5dVpiZs+GQoXS/v2IiEiWYdMIcWRkJKVKlQKgVKlSnDx50nqsY8eOjB8/Pk2CE5EcIjTUTH7vH8GN2x40CI4ehb//jn+7cAEuXoTIyKTbrlIFrlwx20tMUJC5mEbRomnzXkREJMuxKSF+5JFHuHjxInXq1KFUqVLcvn2bS5cuUaJECZydnQkODk7rOEUkO3NySnoENyDAnAGiSxfzIrjEODjAI4/A44+bNcBxt8cfh9Kl4dFHzRKMxJJid3dzZTkREcmxbEqIW7ZsyYwZM8ibNy+tWrWiTJkyzJo1izfeeIPFixfz2GOPpXWcIpKdBQU9eAT36lV46imIiIif9MY9fuQRM6lOSmgo+PjEH4GO4+Nj1io7O6fBGxERkazIpoR40KBBXLhwgbVr19KqVStGjRrFoEGD2LJlC46OjsycOTOt4xSR7Mzd/cEjuI88Ahs32t6+q6s5mwSYI85xF+35+Jj775+XWEREchSbEuLcuXMTEBBAVFQUAA0bNmTLli0cO3aMKlWqaIRYRFLnxg2zTnjixITH0moE18UFfH0xRo8m9uZNHAoWxBIVpWRYRERsS4iDg4MJCAjg559/JiQkJMFxi8XCzp07Hzo4EckBzp+HHj1g3TpzCrTZs9NvBNfVlbA7dzh37Rql8+cnb1pM6SYiIlmeTQnx2LFj2bVrFw0bNqRChQppHZOI5BTXrkGrVnDqFPTpA0uXwpgx5qwPbm7myHA6jOCGJzeVm4iI5Cg2JcT79u1jzJgxWo1ORGx35w60b28mwyVLwscf353tIW4KNF3oJiIiGcCmhTlcXV0pUaJEWsciIjlFdDS8/DIcOAAFC5pLJz/6qL2jEhGRHMqmhLhr164sWrSI0NDQtI5HRLI7w4A334QtW8xyiC1boGJFe0clIiI5mE0lE926dWPDhg00btyY0qVLkydPnnjHLRYLn3/+eZoEKCLZzHvvwaJF5mIaK1fCk0/aOyIREcnhbBohHjduHOfOnaNYsWK4uLhgGEa8W2xsbFrHKSLZwfz5dxfH+PhjeP55+8YjIiKCjSPE3333He+88w5vvPFGWscjItnVxo0wYID5eNw46NfPruGIiIjEsWmE2NnZmSpVqqR1LCKSXe3dC6++CrGx5vRq771n74hERESsbEqIn3/+eb788kuVRohI8k6cMKdXCw+Hdu3gk0/MBThEREQyCZtKJvLnz8/atWtp1qwZ1apVw/W+1Z4sFguTJ09OkwBFJAv75x9z4Y2bN6F+fVi1Chxt+rUjIiKSbmz6n2n9+vW4/f8E+seOHUtw3KLRHxEJCoJnn4WLF6F8edi8GfLmtXdUIiIiCdh8UZ2ISJLCw+GFF+D338HT01x4o0gRe0clIiKSKJtqiEVEkhQbCz16wI8/Qv788M03UKqUvaMSERFJkhJiEUk7hgFvvw1r1oCTkznVWo0a9o5KRETkgZQQi0jamT4dAgLMx0uXQrNm9o1HREQkBZQQi0ja+OILGDHCfDxzJrzyin3jERERSSElxCLy8LZvh9dfNx8PG2aWTYiIiGQRdk+Ig4KCGDduHI0aNaJWrVq8+uqrHD582Hp8//79dOzYkerVq9O6dWu2bt0a7/kRERG8//77NGjQgJo1a/LOO+9w48aNeOck14aIPITDh6FTJ4iOhq5dYepUe0ckIiKSKnZPiIcOHcovv/zCzJkzWbduHRUrVqR3796cPXuWM2fO0K9fPxo2bMj69et58cUX8fX1Zf/+/dbnv/fee/zvf/9j9uzZfP7555w9exYfHx/r8ZS0ISI2OncO2raF0FBo3hwWLwYHu/9aERERSRW7Lhl14cIF9u7dy4oVK6hduzYAY8eOZc+ePWzevJnr169Tvnx53v7/r1/Lli3L8ePHWbhwIQ0aNODy5cts3LiRefPmUadOHQBmzpxJ69at+eWXX6hZsyaff/75A9sQkVQKDTVnkLh5E4oVg/nzzfrhzz4DZ2d7RyciIpJqdh3KKViwIAsWLKBq1arWfRaLBYvFQkhICIcPH06QtNavX58jR45gGAZHjhyx7otTunRpPDw8OHToEECybYhIKoSHw7Rp4OFhLrhRogQcOQLLlplzDouIiGRBdh0hLlCgAI0bN463b/v27Vy4cIF3332XDRs24OnpGe94sWLFCAsL4+bNm1y+fJmCBQuSO3fuBOcEBgYCEBgY+MA2ChUqZFPshmFw584d63ZYWFi8e8n61Kfx5Y6JwcHfH4uf392dQUEwcSKGgwOx77xDhKNdf6WkiPo1+1GfZj/q0+wpo/vVMAwsFkuKzs1U/3v9/PPPjBo1ipYtW9KkSRPCw8Nxvu8r2LjtyMhIwsLCEhwHyJ07NxEREQDJtmGrqKgoTpw4kWD/+fPnbW5TMif1KTg6OlK1QgUscXMM38cSEIDl3Xf56+RJoqOjMzg626hfsx/1afajPs2eMrJfE8sTE5NpEuKdO3cybNgwatWqhb+/P2AmtvcnrXHbefLkwcXFJdGkNiIigjx58qSoDVs5OTlRrlw563ZYWBjnz5+nVKlSD9WuZB7q07tyHTmCJTDQHBFOTFAQluBgvLy8Mn0pkvo1+1GfZj/q0+wpo/v19OnTKT43UyTEy5YtY9KkSbRu3ZqpU6das/nixYtz5cqVeOdeuXKFvHnzkj9/fjw9PQkKCiIyMjLeXwBXrlzBw8MjRW3YymKxkDdv3gT78+TJk+h+ybpydJ8ePw6+vnDwIJw/D+7uiSfF7u5Y3N3Jk4UuqsvR/ZpNqU+zH/Vp9pRR/ZrScgnIBNOurVixggkTJtC1a1dmzpwZL7GtU6cOP/30U7zzDxw4QK1atXBwcKB27drExsZaL64DOHfuHJcvX8bb2ztFbYhIIi5fhjffhKpVYetWMwn+80+4Z0rDeHx8ICoqQ0MUERFJK3bNCM+dO8fkyZNp0aIF/fr149q1a1y9epWrV69y69Ytunfvzm+//Ya/vz9nzpxh8eLFbNu2jT59+gDg4eFB27ZtGTNmDAcPHuS3335j6NCh1K1blxo1agAk24aI3OPOHZg0CcqVM6dTi42FF16AY8egVi0YNQrGjTNHisG8HzfO3O/qasfARUREbGfXkont27cTFRXFjh072LFjR7xjHTp04IMPPuDjjz9m+vTpfP7555QoUYLp06fHm0ZtwoQJTJ48mUGDBgHQqFEjxowZYz3+xBNPJNuGSI4XG2vOJTx6NPzzj7nP2xv8/aFRo7vnubiYJRSjR0NwMLi5mSPDLi72iVtERCQN2DUhfvPNN3nzzTcfeE6jRo1odO9/yPfJmzcvEydOZOLEiTa3IZKj7doFw4bB0aPm9uOPw5Qp8PLLia86FzcSXLSoeZ+F6oZFREQSkykuqhMROzh+HIYPh6+/Nrfd3MyR38GDNeIrIiI5ihJikZwmMBDeew8+/dQslXB0hP79zVrgIkXsHZ2IiEiGU0IsklPcuQMzZ8LUqXD7trmvQwf44APw8rJvbCIiInakhFgkuwkNBScnc6o0d3eIjIQdO2DQIPj3X/Mcb2+YMQMaNrRnpCIiIpmCJuIVyU7Cw2HaNPDwuHubOhWefhoKFDAvmPvySzhwQMmwiIjI/9MIsUh2ERpqJsN+fnf3BQVB3Awsa9dC2bK6YE5EROQ+GiEWyapiY+HUKVi92lxMw2KBgIDEz50zB554QsmwiIhIIjRCLGIP99f5RkU9eKW3O3fg99/NuYJ//dW8/+03sx2AKlWgSxezvcQEBZkLacTNHSwiIiJWSohFMlpcnW9AwN2E2MfHXP7YxcWcFu3o0fjJ76lT5ojw/VxcoGpVs0a4eHGzrcSSYnd3c55hERERSUAJsUhGSqrO188PDAPq14e2bRN/brFiULMmVK8ONWqYtyeeMOcRjmvbxyd+23F8fMxRaK0qJyIikoASYpGM5OSUdJ3v7NkwYoRZ1lC4sJnw3pv8eno+uG1XV3OUGZIefRYREZEElBCLZKSgoAfX+d66BefPQ968trXv4gK+vuYSzMHBZplEVJSSYRERkQdQQiySkQoUeHCdb6FCD1/WEHdxXtwFdCqTEBEReSBNuyaSUT74ALZvN1eMS0xcna+IiIhkKI0Qi6Q3wzBreKdOhQoVzFXiHBxU5ysiIpJJKCEWSU8xMTBwIMyfb2737m3W9arOV0REJNNQQiySXiIjoUcPWLXKXEVuwQLo08c8pjpfERGRTEMJsUh6uHMHOneGb74xp1pbvhxefNHeUYmIiEgilBCLpLXgYGjfHvbsgTx5YP16aN3a3lGJiIhIEpQQi6Slq1ehVSv45RezNnjLFnNZZREREcm0lBCLpJWLF6FFC/jzT7M2+NtvzRXmREREJFNTQiySFk6dMpPhv/+Gxx6DnTvBy8veUYmIiEgKaGEOkYd19Cg0bGgmw15e8L//KRkWERHJQpQQizyMvXuhSRO4csUsj9izB0qWtHdUIiIikgpKiEVstX27WSYRHGxeOPf991CsmL2jEhERkVRSQixii7VrzanVwsLMKdW2bzeXYBYREZEsRwmxSGotWgQvv2wut/zSS7BpE+TNa++oRERExEZKiEVSY8YMc/nl2Fh44w1YsULLLouIiGRxSohFHsDFxcV8YBgwZgwMG2Zu+/rC/PmQK5f9ghMREZE0oXmIRRITGkoeJycqFC6Mg6Mj/PwzrFtnHpsyBUaOtG98IiIikmY0Qixyv/BwmDYNi4cHuYoXx+LhARs3wu7dZomEkmEREZFsRSPEIvcKDYVp08DP7+6+oCCYOBEcHMxSCREREclWNEIsci8nJwgISPxYQIB5XERERLIVJcQicaKj4do1c0Q4MUFB5iIcIiIikq0oIRaJiIBPP4X69cHNLekFNtzdzeMiIiKSrSghlpwrLAxmz4Zy5aBvXzhyxLxwbvDgxM/38TEX4xAREZFsRRfVSc5z6xbMm2cusnH5srnvkUfMC+aaNIGmTcFiMWuGg4LMkWEfHxg1CuLmJRYREZFsQwmx5BxBQeaI8KxZcOOGua9UKXMatZ49IXfuu+f6+mKMHk3szZs4FCyIJSpKybCIiEg2pYRYsr9r18wkePZsCAkx9z3xBLz7LnTtmvjMEa6uhN25w7lr1yidPz95XV0zNGQRERHJOEqIJfv67z+zLOKTT+DOHXNflSowejS8+GKKll0ODw9P5yBFRETE3pQQS9YVGmqO7sbV+UZFgasr/P23ubjGwoXmDBIAtWrB2LHw3HPmAhsiIiIi/0+ZgWRN/7+8Mh4ed2/TppnJcdu2MHeumQw3aABffw2HD8MLLygZFhERkQQ0QixZT1LLK/v5QWwsTJhg1guPGWPOGmGx2CtSERERyQKUEEvW86DllefMgcBAczRYREREJAX0/bFkPUFBD15eOW4mCREREZEUUEIsWcutW5A/v5ZXFhERkTST6RLi+fPn071793j7Tpw4Qbdu3ahRowbNmjVj6dKl8Y7HxsYSEBBAw4YNqVGjBm+88QYXL15MVRuSBezdC9WqwbffwqBBiZ+j5ZVFREQklTJVQrx8+XJmzZoVb9/Nmzfp1asXJUuWZN26dQwcOBB/f3/WrVtnPefjjz9mxYoVTJgwgZUrVxIbG0ufPn2IjIxMcRuSiUVFmVOmNWoE58+b9cMjR8K4cXdHit3dze1Ro8yp10RERERSKFNcVHf58mXGjx/PwYMHKVWqVLxjq1evxsnJCT8/PxwdHSlbtiwXLlxgwYIFdOrUicjISBYvXsywYcNo0qQJAB9++CENGzbk22+/pV27dsm2IZnYqVPQrRscOmRu9+hhJsSuruDray6yERxslkloeWURERGxQaYYIf7jjz9wcnLiq6++onr16vGOHT58mLp16+LoeDd3r1+/PufPn+fatWucPHmS0NBQGjRoYD1eoEABKlWqxKH/T6KSa0MyIcOABQugZk0zGXZ3h1Wr4PPP79YIu7qCszMULWrea2RYREREbJApRoibNWtGs2bNEj0WGBiIl5dXvH3FihUD4L///iMwMBCA4sWLJzgn7lhybRQpUiTVMRuGwZ245YCBsLCwePfyEK5exXngQBy3bgUgpnFjIj/9FOPRR+8uwZwB1KfZk/o1+1GfZj/q0+wpo/vVMAwsKVyLIFMkxA8SHh6Os7NzvH25c+cGICIiwvpDTeyc4ODgFLVhi6ioKE6cOJFg//nz521qT0wF/vc/Sk2YgOP168Q6OfHPwIFc6dLFnErNTtOpqU+zJ/Vr9qM+zX7Up9lTRvbr/flfUjJ9Quzi4mK9OC5OXBKbN29eXP6/ZjQyMtL6OO6cPHnypKgNWzg5OVGuXDnrdlhYGOfPn6dUqVLW15VUuHMHpzFjcJo/H4DYihWJWLyYwtWqUdhOIalPsyf1a/ajPs1+1KfZU0b36+nTp1N8bqZPiD09Pbly5Uq8fXHbHh4eREdHW/eVLFky3jnly5dPURu2sFgsiSbTefLksTnJzrF+/tm8cC5uxP2tt3CYMiXT/BJUn2ZP6tfsR32a/ahPs6eM6teUlktAJrmo7kG8vb05cuQIMTEx1n0HDhygdOnSFC5cmAoVKpAvXz4OHjxoPR4SEsLx48fx9vZOURtiJzExMHUq1K9vJsOenrBtG8yaBZkkGRYREZHsL9MnxJ06deL27duMHj2a06dPs379ej777DP69esHmLUh3bp1w9/fn127dnHy5EnefvttPD09admyZYraEDv4+2945hlzPuGoKOjQAX7/HVq1sndkIiIiksNk+pKJwoULs3DhQiZNmkSHDh0oWrQovr6+dOjQwXqOj48P0dHRjBkzhvDwcLy9vVm0aBFOTk4pbkMy0IoVMGCAOX+wq6s5r3CvXpCKrzZERERE0kqmS4g/+OCDBPuqVavGqlWrknxOrly5GD58OMOHD0/ynOTakHQQGgpOThAUZM4jHBYGEyeCv795vH59WLYMypa1Z5QiIiKSw2X6kgnJosLDYdo08PC4e/P3N1eXq1wZ3nsP9uxRMiwiIiJ2l+lGiCUbCA01k2E/v7v7goLM0WGAb7+FRx6xS2giIiIi99MIsaQ9JyezLjgxc+aADSsDioiIiKQXJcSS9m7eNEeEExMUZF5MJyIiIpJJKCGWtHPnjjmvcL585kV0iXF3Bze3jIxKRERE5IGUEMvDMwxYswYqVDDnFd65EwYPTvxcHx9z3mERERGRTEIX1cnD+f13M8n94Qdzu2RJc5W5d9815xUOCLg77ZqPD4waBS4udgxYREREJD4lxGKbGzdg3Dj45BOIjTWT3JEjYfhwiFuf3NcXRo82a4bd3MyRYSXDIiIikskoIZbUiYmBTz81E90bN8x9nTubcww//nj8c11dzfuiRc17Z+eMi1NEREQkhZQQS8rt3m2WPfz6q7ldubJZEtGsmX3jEhEREXkIuqhOknfxIrz6KjRubCbD7u4wezYcPapkWERERLI8jRBL0sLDYcYMmDzZnFLNYoG+fc0V57S4hoiIiGQTSoglIcOATZtg6FA4d87c9/TTZnlEzZr2jU1EREQkjalkIqcLDYXISLhy5e59nz7QoYOZDD/6KKxYYdYPKxkWERGRbEgJcU4WHg7TpoGHx93b7NnwwQdQrZo5l/DJk2b9sMVi72hFRERE0oVKJnKq0FAzGfbzu7svKMisD7ZYYNcu1QmLiIhIjqAR4pzKycmsCU7M7NlQoEDGxiMiIiJiJ0qIc6I//oDAQHNEODFBQebqciIiIiI5gBLinOTsWbMeuEkTKFzYnE84Me7u5lLLIiIiIjmAEuKc4No1GDIEKlSAlSvh+nVzlNjHJ/HzfXwgKipDQxQRERGxF11Ul53duQOzZsHUqRASYu5r2dLcrlHDnEkCzFrioCBzZNjHB0aNAhcX+8QsIiIiksGUEGdHMTHw2Wcwbhz8+6+5r0YNc1aJFi3unufiAr6+MHq0WTPs5maODCsZFhERkRxECXF2YhiwdSuMHGmWRAA8/jhMmmTWDjskUiHj6mreFy1q3js7Z0ysIiIiIpmEEuLs4qefYPhwc0U5gIIFYcwYGDgQcue2b2wiIiIimZgS4qzu9GlzRbk1a8zt3LnNC+hGjkx6FgkRERERsVJCnNmFhpqLaMRd9BYVZZY5XLkCEybAvHkQHW2uLvfaa+bKc489Zu+oRURERLIMTbuWmYWHmxfCeXjcvU2bZl4A16YNzJljJsPPPgtHj8KSJUqGRURERFJJI8SZVWiomfz6+d3dFxRkbsfGmvXBEyea5zRrZrcwRURERLI6JcSZlZOTOT9wYubMgf/+g+eeS3zmCBERERFJMWVTmVVQkHlL6titW0qGRURERNKAMqrMyt096Vki3N3NRTRERERE5KEpIc6soqLMZZQT4+NjHhcRERGRh6Ya4szK1RVGjTIfBwTcnXbNx8fcr+WVRURERNKEEuLMzMUFfH1h9GhzqjU3N3NkWMmwiIiISJpRQpzZubqa90WLmvfOzvaLRURERCQbUg2xiIiIiORoSohFREREJEdTQiwiIiIiOZoSYhERERHJ0ZQQi4iIiEiOpoRYRERERHI0JcQiIiIikqMpIRYRERGRHE0JsYiIiIjkaEqIRURERCRHU0IsIiIiIjmaxTAMw95BZDU///wzhmHg7Oxs3WcYBlFRUTg5OWGxWOwYnaQV9Wn2pH7NftSn2Y/6NHvK6H6NjIzEYrFQq1atZM91TPdosqHEOtFiscRLkCXrU59mT+rX7Ed9mv2oT7OnjO5Xi8WS4sRbI8QiIiIikqOphlhEREREcjQlxCIiIiKSoykhFhEREZEcTQmxiIiIiORoSohFREREJEdTQiwiIiIiOZoSYhERERHJ0ZQQi4iIiEiOpoRYRERERHI0JcQiIiIikqMpIRYRERGRHE0JsYiIiIjkaEqIH1JsbCwBAQE0bNiQGjVq8MYbb3Dx4kV7hyUP6fLly5QvXz7Bbf369fYOTWwwf/58unfvHm/fiRMn6NatGzVq1KBZs2YsXbrUTtGJLRLr0zFjxiT4zDZr1sxOEUpKBAUFMW7cOBo1akStWrV49dVXOXz4sPX4/v376dixI9WrV6d169Zs3brVjtFKSiXXr7169UrwWb3/85zRHO366tnAxx9/zIoVK/jggw/w9PRk+vTp9OnTh82bN+Ps7Gzv8MRGJ0+eJHfu3OzcuROLxWLdnz9/fjtGJbZYvnw5s2bNok6dOtZ9N2/epFevXjRr1oz333+fo0eP8v777+Pq6kqnTp3sGK2kRGJ9CvDnn3/y5ptv0q1bN+u+XLlyZXR4kgpDhw7l6tWrzJw5k8KFC/PFF1/Qu3dvNmzYgGEY9OvXj169ejF9+nR++OEHfH19KVSoEA0aNLB36PIAD+rXMmXK8Oeff/Lee+/RvHlz63OcnJzsGLES4ocSGRnJ4sWLGTZsGE2aNAHgww8/pGHDhnz77be0a9fOvgGKzU6dOkWpUqUoVqyYvUMRG12+fJnx48dz8OBBSpUqFe/Y6tWrcXJyws/PD0dHR8qWLcuFCxdYsGCBEuJM7EF9ahgGp0+fpm/fvhQtWtQ+AUqqXLhwgb1797JixQpq164NwNixY9mzZw+bN2/m+vXrlC9fnrfffhuAsmXLcvz4cRYuXKiEOBNLrl+7devG9evXqV69eqb6rKpk4iGcPHmS0NDQeB/MAgUKUKlSJQ4dOmTHyORh/fnnn5QtW9beYchD+OOPP3BycuKrr76ievXq8Y4dPnyYunXr4uh4d0ygfv36nD9/nmvXrmV0qJJCD+rTv//+mzt37lCmTBk7RSepVbBgQRYsWEDVqlWt+ywWCxaLhZCQEA4fPpwg8a1fvz5HjhzBMIyMDldSKLl+/fPPP7FYLJQuXdqOUSakhPghBAYGAlC8ePF4+4sVK2Y9JlnTqVOnuHHjBl27duXJJ5/k1VdfZffu3fYOS1KhWbNmzJ49m8ceeyzBscDAQDw9PePti/s24L///suQ+CT1HtSnp06dAuCLL76gWbNmNG/eHD8/P27dupXRYUoKFShQgMaNG8crL9y+fTsXLlygYcOGSX5Ow8LCuHnzZkaHKymUXL+eOnWK/Pnz4+fnR6NGjWjdujWzZs0iMjLSjlErIX4oYWFhAAlqhXPnzk1ERIQ9QpI0EB0dzdmzZwkODmbw4MEsWLCAGjVq0LdvX/bv32/v8CQNhIeHJ/q5BfTZzaJOnTqFg4MDxYoVY968eYwcOZL//e9/DBgwgNjYWHuHJynw888/M2rUKFq2bEmTJk0S/ZzGbds7eZKUu79fT506RUREBNWqVWPhwoX079+fNWvWMGbMGLvGqRrih+Di4gKYH8y4x2D+h5onTx57hSUPydHRkYMHD5IrVy5rv1apUoW//vqLRYsWqXYtG3BxcUnwH2pcIpw3b157hCQPqX///nTp0oWCBQsC4OXlRdGiRXnppZf4/fffE5RYSOayc+dOhg0bRq1atfD39wfMP1Lv/5zGbev/2KwhsX718/NjxIgRuLm5AeZn1cnJibfffhtfX1+KFClil1g1QvwQ4kolrly5Em//lStX8PDwsEdIkkZcXV3j/ZED8MQTT3D58mU7RSRpydPTM9HPLaDPbhbl4OBgTYbjPPHEEwAqYcvkli1bxuDBg2natCnz5s2zfltTvHjxRD+nefPm1Yw/WUBS/ero6GhNhuNkhs+qEuKHUKFCBfLly8fBgwet+0JCQjh+/Dje3t52jEwexl9//UWtWrXi9SvAsWPHKFeunJ2ikrTk7e3NkSNHiImJse47cOAApUuXpnDhwnaMTGzl6+tLz5494+37/fffAfS5zcRWrFjBhAkT6Nq1KzNnzoxXIlGnTh1++umneOcfOHCAWrVq4eCg9CUze1C/du/enVGjRsU7//fff8fJySnB7DEZSf+iHoKzszPdunXD39+fXbt2cfLkSd5++208PT1p2bKlvcMTG5UtW5YyZcrg5+fH4cOHOXPmDFOmTOHo0aP079/f3uFJGujUqRO3b99m9OjRnD59mvXr1/PZZ5/Rr18/e4cmNmrVqhX79+9nzpw5/P333/z444+8++67tGvXTjPGZFLnzp1j8uTJtGjRgn79+nHt2jWuXr3K1atXuXXrFt27d+e3337D39+fM2fOsHjxYrZt20afPn3sHbo8QHL92qpVKzZt2sSXX37JxYsX+frrr5k2bRq9e/cmX758dovbYmjukocSExPDzJkzWb9+PeHh4Xh7ezNu3DhKlChh79DkIVy7do0ZM2awZ88eQkJCqFSpEsOGDUuwEIBkDSNHjuSff/7hiy++sO777bffmDRpEsePH6do0aK8/vrr8RZ0kMwtsT795ptvWLBgAWfPniV//vy0b9+eIUOGWL+qlcxl3rx5fPjhh4ke69ChAx988AG7d+9m+vTpnD9/nhIlSjB48GDatGmTwZFKaqSkX5cvX87y5cu5ePGitda/b9++dh35V0IsIiIiIjmaSiZEREREJEdTQiwiIiIiOZoSYhERERHJ0ZQQi4iIiEiOpoRYRERERHI0JcQiIiIikqMpIRYRyaI0a6aISNpQQiwikoGaNWvGyJEjH6qNkJAQfH19OXz4cIqfM3v2bMqXL/9Qr5tS3bt3p3v37hnyWiIiacHR3gGIiEjqnDhxgk2bNtGpUyd7h5Ko8ePH2zsEEZFUUUIsIiJpqly5cvYOQUQkVVQyISKSwaKiopg4cSLe3t7UqVOHESNGcOPGDevxNWvW0LFjR2rUqEG1atV4/vnn+eabbwA4ePAgPXr0AKBHjx7xShM2btxIhw4dqF69Ok2aNGHGjBlERkbGe+0ffviB5557jqpVq9KqVSs2btyY6vj37t3LSy+9RM2aNfH29qZ///6cOXPGevzekon169dTvnz5RG/3lo4cPnyYbt26Ub16derWrZvgZyIikp4shq7KEBHJMM2aNSMwMJDq1avTp08fbty4gb+/PyVKlGD16tWsXLmSiRMnMnjwYGrXrk1wcDCffvopx48fZ9euXeTLl49Nmzbh5+fHuHHjqFevHuXKlWP58uX4+fnx4osv0qpVKy5evMi0adN47rnn8PPzY/bs2cyZMwcPDw+GDBlCsWLF+PTTTzl48CAbN26kQoUKKYr/4sWLtGvXjk6dOtGyZUtCQkKYOXMmUVFR7NixAwcHB2sy/MUXX3Djxg3+/vvveG0sWbKEnTt3snjxYurVq8ehQ4fo1asX9evXp2vXrgQHB/PRRx/h6urK2rVrcXFxSfN+EBG5l0omREQyWMGCBVm0aBF58+a1bg8cOJDdu3dz8eJFevfuzYABA6znP/roo3Ts2JEjR47Qtm1ba0lCuXLlKFeuHLGxscydO5fmzZszceJE6/PCwsLYunUrUVFR1n0TJ06kUaNGAJQsWZIWLVrw008/pTgh/u233wgPD6dfv354eHgA4Onpya5du7hz5w758uWLd36hQoUoVKiQdXvHjh1s376dd999l3r16gEwY8YMSpcuzfz588mVKxcA1atXp23btqxbt46uXbum7AcrImIjJcQiIhmscePG1mQYzFFjR0dHDh06ZC0jCAkJ4ezZs1y4cIGDBw8CJCh/iHPu3DmuX79OixYt4u3v3bs3vXv3jrevTp061sclSpSwvlZKVa9endy5c9O5c2dat25No0aNqFevHtWqVUv2uSdPnsTX15cXXnjBWvYRFhbGr7/+Su/evTEMg+joaAAee+wxypYty969e5UQi0i6U0IsIpLBihYtGm/bwcGBggULEhISwt9//824cePYv38/Tk5OlClTxjp6m1SFW1BQEACFCxdO9rXvTcQdHBwe2G5iSpQowbJly1iwYAFr165l6dKlFChQgC5dujBkyBAsFkuiz7t+/Tr9+/enTJkyvP/++9b9ISEhxMbG8umnn/Lpp58meF7u3LlTHJuIiK2UEIuIZLC4BDZOTEwMN2/epGDBgvTt2xcnJyfWrl1LxYoVcXR05PTp02zatCnJ9goUKACQ4CK0mzdvcvz4cWrWrJmm8VerVo05c+YQGRnJkSNHWLVqFfPmzaNChQo8++yzCc6PjIxk4MCBREREMHfu3HhJrqurKxaLhZ49e9K2bdsEz82TJ0+axi4ikhjNMiEiksH27t1rLQ0A2L59O9HR0VSsWJFz587RuXNnqlatiqOjOWaxe/duAGJjYwGsdbZxypQpQ8GCBfn+++/j7d+0aRN9+/aNV0P8sD777DOaNm1KZGQkzs7ONGjQgAkTJgDw77//Jvqc8ePHc+zYMQICAvD09Ix3LF++fFSqVImzZ89StWpV6+2JJ55g9uzZ1nIREZH0pBFiEZEMdvXqVQYPHkz37t05f/48M2fO5KmnnuLZZ5/F39+f5cuX4+npSYECBdizZw9Lly4FzHpbgPz58wPmFGpubm5UqFCBwYMH4+fnR+HChWnWrBnnzp0jICCArl274ubmlmax169fH39/fwYOHEi3bt3IlSsXK1euxNnZmaZNmyY4/7PPPmP9+vW8/vrr5MmTh6NHj1qPOTs7U6lSJYYOHUrfvn155513eO6554iJiWHx4sX8+uuv8S4uFBFJL0qIRUQyWJcuXbh16xYDBw7E2dmZ9u3bM3z4cCwWCx9//DGTJk1i5MiRODs7U65cOT755BMmT57M4cOH6d69O0888QTt2rVj+fLl7Nmzhy1bttC1a1fy5s3LokWLWLVqFZ6enrzxxhu88cYbaRp7hQoVmDdvHnPnzmXo0KHExMRQpUoVFi9eTJkyZRKcv2vXLgAWL17M4sWL4x179NFH+e6773j66adZtGgRc+bMwcfHBycnJypXrsySJUuoUaNGmsYvIpIYzUMsIiIiIjmaRohFRITY2FhrjfKDxNU1i4hkJxohFhERRo4cyYYNG5I9788//8yAaEREMpYSYhER4dKlS9y8eTPZ86pWrZoB0YiIZCwlxCIiIiKSo2keYhERERHJ0ZQQi4iIiEiOpoRYRERERHI0JcQiIiIikqMpIRYRERGRHE0JsYiIiIjkaEqIRURERCRHU0IsIiIiIjna/wH+uGrmCPVxuQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =======================================\n",
    "# PLOTS\n",
    "# =======================================\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Tempo por época\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=df, x=\"batch_size\", y=\"time_per_epoch_ns\", marker=\"o\")\n",
    "plt.title(\"Tempo médio por época x Batch Size\")\n",
    "plt.show()\n",
    "\n",
    "# Memória GPU\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=df, x=\"batch_size\", y=\"max_memory_MB\", marker=\"o\", color=\"red\")\n",
    "plt.title(\"Consumo máximo de memória (MB) x Batch Size\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
